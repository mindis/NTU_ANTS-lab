{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys,glob\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "from keras.utils import *\n",
    "from keras.utils.generic_utils import *\n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import *\n",
    "from keras.preprocessing.image import *\n",
    "from multiprocessing import *\n",
    "import gensim\n",
    "from gensim.models.word2vec import *\n",
    "from sklearn.metrics.pairwise import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.manifold import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.cluster import *\n",
    "from sklearn import preprocessing\n",
    "import sent2vec\n",
    "import re\n",
    "import string\n",
    "import unicodedata as udata\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from collections import OrderedDict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sent2vec.Sent2vecModel()\n",
    "model.load_model('model/o2o_o2m_Sent2Vec_lower_woParam_0616_768.bin') # sent2vec model\n",
    "dil= r\"[,.;\\-+^()/@#?!&$:{}\\\\*%~\\'\\\"\\=\\_]+\\ *\" #等號、底線被保留，注意要跟先前一致\n",
    "# all_df = pd.read_csv('./data/tree-rep-profiles-partial/process2family_df.csv')\n",
    "api_li = ['LoadLibrary',\n",
    "'CreateProcess',\n",
    "'OpenProcess',\n",
    "'ExitProcess',\n",
    "'TerminateProcess',\n",
    "'WinExec',\n",
    "'CreateRemoteThread',\n",
    "'CreateThread',\n",
    "'CopyFile',\n",
    "'CreateFile',\n",
    "'DeleteFile',\n",
    "'RegSetValue',\n",
    "'RegCreateKey',\n",
    "'RegDeleteKey',\n",
    "'RegDeleteValue',\n",
    "'RegQueryValue',\n",
    "'RegEnumValue',\n",
    "'WinHttpConnect',\n",
    "'WinHttpOpen',\n",
    "'WinHttpOpenRequest',\n",
    "'WinHttpReadData',\n",
    "'WinHttpSendRequest',\n",
    "# 'WinHttpWriteData', #少了\n",
    "'InternetOpen',\n",
    "'InternetConnect',\n",
    "'HttpSendRequest',\n",
    "'GetUrlCacheEntryInfo']\n",
    "api_li = [x.lower() for x in api_li] #lowrer case?\n",
    "len(api_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loadlibrary': 1,\n",
       " 'createprocess': 2,\n",
       " 'openprocess': 3,\n",
       " 'exitprocess': 4,\n",
       " 'terminateprocess': 5,\n",
       " 'winexec': 6,\n",
       " 'createremotethread': 7,\n",
       " 'createthread': 8,\n",
       " 'copyfile': 9,\n",
       " 'createfile': 10,\n",
       " 'deletefile': 11,\n",
       " 'regsetvalue': 12,\n",
       " 'regcreatekey': 13,\n",
       " 'regdeletekey': 14,\n",
       " 'regdeletevalue': 15,\n",
       " 'regqueryvalue': 16,\n",
       " 'regenumvalue': 17,\n",
       " 'winhttpconnect': 18,\n",
       " 'winhttpopen': 19,\n",
       " 'winhttpopenrequest': 20,\n",
       " 'winhttpreaddata': 21,\n",
       " 'winhttpsendrequest': 22,\n",
       " 'internetopen': 23,\n",
       " 'internetconnect': 24,\n",
       " 'httpsendrequest': 25,\n",
       " 'geturlcacheentryinfo': 26}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_dict = {}\n",
    "for i,v in enumerate(api_li):\n",
    "    encode_dict[v] = i+1\n",
    "pickle.dump(file=open('data/tree-rep-profiles_o2o/encode_dict.pkl','wb'),obj=encode_dict)\n",
    "encode_dict\n",
    "# encode_dict = pickle.load(open('data/tree-rep-profiles-partial/encode_dict.pkl','rb'))\n",
    "# encode_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sent2vec_emb(root_dir,dev=False,max_length=216,model=model,dim=768,encode_dict=encode_dict,dil=dil):\n",
    "    # root_dir = './data/tree-rep-profiles_one2many/'\n",
    "#     samples_pid_aliases = []\n",
    "#     processed_pid = []\n",
    "#     rasmma_dir = next(os.walk(root_dir))[1]\n",
    "#     samples_pid_valid = valid_pids_df.index.tolist()\n",
    "#     samples_pid_test = test_pids_df.index.tolist()\n",
    "    # max_length = 347\n",
    "    # dim = 768\n",
    "\n",
    "    dev_pids_path = [] #儲存profile順序?\n",
    "    \n",
    "    sent_pad = [0]*dim\n",
    "    # encode_dict = encode_dict_lower\n",
    "    all_profiles = []\n",
    "    all_api_name = []\n",
    "    all_fam_ans = []\n",
    "    all_byterep=[]\n",
    "    hl_rep = []\n",
    "    sen2vec_length_normalize = []\n",
    "    sen2vec_dim_normalize = []\n",
    "    loner = False\n",
    "    if root_dir.split('/')[-2] in 'EXP': #partial match EXP dir\n",
    "        loner = True\n",
    "#     for rasmma in rasmma_dir:\n",
    "    fam_dir = next(os.walk(root_dir))[1]\n",
    "    for fam in tqdm(fam_dir):\n",
    "        tree_dir = next(os.walk(root_dir +fam))[1]\n",
    "        for tree in tree_dir:\n",
    "            in_directory = root_dir + fam +  '/' + tree + '/'\n",
    "            hl_list = next(os.walk(in_directory))[2]\n",
    "            hl_list = [os.path.join(in_directory, f) for f in hl_list]\n",
    "            hl_list = list(filter(lambda f: f.endswith(\".profile\"), hl_list))\n",
    "            for hl_f in hl_list:\n",
    "                profile_emb = [] #整個api invocation call\n",
    "                func_name_emb = [] #僅有api function name\n",
    "                if not loner:\n",
    "                    byterep = hl_f.replace('.profile','_byterep.pickle') #拿出hl_f所對應的byterep\n",
    "                    rep = pickle.load(open(byterep,'rb')) #list type\n",
    "                    if len(rep) < max_length: #Y1\n",
    "                        for _ in range(max_length-len(rep)):\n",
    "                            rep.append(0)\n",
    "                with open(hl_f,encoding='ISO 8859-1') as f: #X2\n",
    "                    lines = f.read()\n",
    "                lines = re.sub(r'[^\\x00-\\x7F]+','', lines)\n",
    "                lines = re.sub(r'[\\x1e\\x7f\\x15\\x10\\x0c\\x1c]+','', lines)\n",
    "                lines = lines.splitlines()\n",
    "                if len(lines) > max_length:\n",
    "                    print(\"ERR length too long:\",hl_f,'=>',len(lines))\n",
    "                    continue\n",
    "                dev_pids_path.append(hl_f)\n",
    "                for line in lines:\n",
    "                    temp = re.sub(dil,\" \",line.lower()) # lower? 跟先前一致\n",
    "                    temp = temp.split(\" \")\n",
    "                    temp = list(filter(None, temp))\n",
    "                    temp = ' '.join(temp)\n",
    "                    func_name = temp.split(' ')[0] # X1\n",
    "                    if func_name not in api_li:\n",
    "                        print('=ERROR:=',hl_f,'=>',temp)\n",
    "                    func_name_emb.append(encode_dict[func_name]) # encode証術數數字\n",
    "                    emb = model.embed_sentence(temp)\n",
    "                    emb = emb[0]\n",
    "                    profile_emb.append(emb) #放入embdding，句子=>profile\n",
    "                    sen2vec_dim_normalize.append(emb) #dim norm用\n",
    "                sen2vec_length_normalize.append(len(lines))\n",
    "                if len(lines) < max_length:\n",
    "                    for _ in range(max_length-len(lines)):\n",
    "                        profile_emb.append(sent_pad)\n",
    "                if not loner:\n",
    "                    hl_rep.append(rep) #Y1\n",
    "                all_profiles.append(profile_emb) #X2\n",
    "                all_api_name.append(func_name_emb) #X1\n",
    "    #             all_byterep.extend(rep_list)\n",
    "    all_api_name = pad_sequences(all_api_name,maxlen=max_length,padding='post',value=0) #X1\n",
    "\n",
    "    if not loner:\n",
    "        return np.array(all_api_name) , np.array(all_profiles) , np.array(hl_rep),np.array(sen2vec_dim_normalize) ,sen2vec_length_normalize, dev_pids_path\n",
    "    else:\n",
    "        return np.array(all_api_name) , np.array(all_profiles) ,np.array(sen2vec_dim_normalize) ,sen2vec_length_normalize,dev_pids_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:26<00:00,  4.03it/s]\n",
      "  2%|▏         | 1/45 [00:00<00:05,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7103, 216) (7103, 216, 768) (7103, 216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:09<00:00,  4.81it/s]\n",
      "  2%|▏         | 1/45 [00:00<00:07,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 216) (451, 216, 768) (451, 216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:10<00:00,  4.18it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 27060.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 216) (506, 216, 768) (506, 216)\n",
      "(0, 216) (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dir = './data/tree-rep-profiles_o2o/normal/'\n",
    "train_api,train_emb, train_rep, train_normalize , train_len_norm,train_pids_path =   Sent2vec_emb(train_dir)\n",
    "print(train_api.shape,train_emb.shape,train_rep.shape)\n",
    "valid_dir = './data/tree-rep-profiles_o2o/DEV/'\n",
    "valid_api,valid_emb, valid_rep, valid_normalize , valid_len_norm,valid_pids_path =   Sent2vec_emb(valid_dir)\n",
    "print(valid_api.shape,valid_emb.shape,valid_rep.shape)\n",
    "test_dir = './data/tree-rep-profiles_o2o/TEST/'\n",
    "test_api,test_emb, test_rep, test_normalize , test_len_norm,test_pids_path =   Sent2vec_emb(test_dir)\n",
    "print(test_api.shape,test_emb.shape,test_rep.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:05<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 216) (318, 216, 768)\n"
     ]
    }
   ],
   "source": [
    "exp_dir = './data/tree-rep-profiles_o2o/EXP/'\n",
    "exp_api,exp_emb, exp_normalize , exp_len_norm,exp_pids_path =   Sent2vec_emb(exp_dir)\n",
    "print(exp_api.shape,exp_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dim normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768,), (768,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls = np.concatenate([train_normalize,valid_normalize,test_normalize,exp_normalize])\n",
    "mean = np.mean(alls,axis=0)\n",
    "std = np.std(alls,axis=0)\n",
    "mean.shape , std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dim(emb,length,mean=mean,std=std):\n",
    "    sent_emb = (emb[:length,:] - mean)/std\n",
    "    final_emb = np.concatenate([sent_emb, emb[length:,:]],axis=0)\n",
    "    return final_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7103, 216, 768) (451, 216, 768) (506, 216, 768) (318, 216, 768)\n"
     ]
    }
   ],
   "source": [
    "test_emb_norm = []\n",
    "valid_emb_norm = []\n",
    "train_emb_norm = []\n",
    "exp_emb_norm = []\n",
    "for emb,length in zip(train_emb,train_len_norm):\n",
    "    emb_norm = normalize_dim(emb,length)\n",
    "    train_emb_norm.append(emb_norm)\n",
    "for emb,length in zip(valid_emb,valid_len_norm):\n",
    "    emb_norm = normalize_dim(emb,length)\n",
    "    valid_emb_norm.append(emb_norm)\n",
    "for emb,length in zip(test_emb,test_len_norm):\n",
    "    emb_norm = normalize_dim(emb,length)\n",
    "    test_emb_norm.append(emb_norm)\n",
    "for emb,length in zip(exp_emb,exp_len_norm):\n",
    "    emb_norm = normalize_dim(emb,length)\n",
    "    exp_emb_norm.append(emb_norm)\n",
    "train_emb = np.array(train_emb_norm)\n",
    "valid_emb = np.array(valid_emb_norm)\n",
    "test_emb = np.array(test_emb_norm)\n",
    "exp_emb = np.array(exp_emb_norm)\n",
    "print(train_emb.shape,valid_emb.shape,test_emb.shape,exp_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './data/tree-rep-profiles_o2o/'\n",
    "pickle.dump(file=open(root_dir + 'pids_train.pkl','wb')\n",
    "            ,obj=(train_api , train_emb , train_rep),protocol=4)\n",
    "pickle.dump(file=open(root_dir + 'pids_valid.pkl','wb')\n",
    "            ,obj=(valid_api,valid_emb,valid_rep),protocol=4)\n",
    "pickle.dump(file=open(root_dir + 'pids_test.pkl','wb')\n",
    "            ,obj=(test_api,test_emb,test_rep),protocol=4)\n",
    "pickle.dump(file=open(root_dir + 'pids_exp.pkl','wb')\n",
    "            ,obj=(exp_api,exp_emb),protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
