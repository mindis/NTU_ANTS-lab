{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os,shutil,pickle,tqdm,sys,random,re,string,pause, datetime,glob\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# # The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" \n",
    "import keras\n",
    "import sent2vec\n",
    "import seq2seq\n",
    "from seq2seq.models import AttentionSeq2Seq\n",
    "from seq2seq.models import Seq2Seq\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils import *\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras import *\n",
    "from keras.engine.topology import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import *\n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import *\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.cluster import *\n",
    "from sklearn.metrics.pairwise import *\n",
    "\n",
    "# from collections import Counter\n",
    "from keras.utils.generic_utils import *\n",
    "from keras import regularizers\n",
    "import unicodedata as udata\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "from keras import backend \n",
    "from imblearn.ensemble import *\n",
    "from imblearn.combine import *\n",
    "# from python.keras import backend \n",
    "# Embedding(10,20)\n",
    "from keras_transformer.extras import ReusableEmbedding, TiedOutputEmbedding\n",
    "from keras_transformer.position import TransformerCoordinateEmbedding\n",
    "from keras_transformer.transformer import TransformerACT, TransformerBlock\n",
    "from keras_transformer.bert import (\n",
    "    BatchGeneratorForBERT, masked_perplexity,\n",
    "    MaskedPenalizedSparseCategoricalCrossentropy)\n",
    "\n",
    "import keras_metrics as km\n",
    "from keras_trans_mask import RemoveMask, RestoreMask\n",
    "\n",
    "from keras_multi_head import *\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val_loss', 'val_bin_acc', 'loss', 'bin_acc']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = './logs/MLP_2dense_0718/'\n",
    "history = pickle.load(open(log_dir+'MLP_3dense_gruatt_H.pkl','rb'))\n",
    "keys = list(history.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_bin_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>bin_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.949592</td>\n",
       "      <td>0.545345</td>\n",
       "      <td>0.679174</td>\n",
       "      <td>0.717514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.628379</td>\n",
       "      <td>0.615690</td>\n",
       "      <td>0.540690</td>\n",
       "      <td>0.775704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.767312</td>\n",
       "      <td>0.611486</td>\n",
       "      <td>0.476352</td>\n",
       "      <td>0.802738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.774234</td>\n",
       "      <td>0.594588</td>\n",
       "      <td>0.477878</td>\n",
       "      <td>0.801393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.354254</td>\n",
       "      <td>0.556720</td>\n",
       "      <td>0.436396</td>\n",
       "      <td>0.846643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.930971</td>\n",
       "      <td>0.562779</td>\n",
       "      <td>0.553420</td>\n",
       "      <td>0.780035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.620704</td>\n",
       "      <td>0.601777</td>\n",
       "      <td>0.491871</td>\n",
       "      <td>0.789665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.601158</td>\n",
       "      <td>0.628626</td>\n",
       "      <td>0.576487</td>\n",
       "      <td>0.716091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.687972</td>\n",
       "      <td>0.592990</td>\n",
       "      <td>0.578266</td>\n",
       "      <td>0.716544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.668036</td>\n",
       "      <td>0.604354</td>\n",
       "      <td>0.504097</td>\n",
       "      <td>0.766543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.723571</td>\n",
       "      <td>0.691834</td>\n",
       "      <td>0.624880</td>\n",
       "      <td>0.697308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.790536</td>\n",
       "      <td>0.590982</td>\n",
       "      <td>0.580731</td>\n",
       "      <td>0.750099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.858920</td>\n",
       "      <td>0.562089</td>\n",
       "      <td>0.507616</td>\n",
       "      <td>0.796905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.171883</td>\n",
       "      <td>0.671907</td>\n",
       "      <td>0.628383</td>\n",
       "      <td>0.777093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.668152</td>\n",
       "      <td>0.580948</td>\n",
       "      <td>0.546803</td>\n",
       "      <td>0.750103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.854895</td>\n",
       "      <td>0.664171</td>\n",
       "      <td>0.550152</td>\n",
       "      <td>0.693426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.620715</td>\n",
       "      <td>0.590396</td>\n",
       "      <td>0.574091</td>\n",
       "      <td>0.708292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.606592</td>\n",
       "      <td>0.610861</td>\n",
       "      <td>0.614475</td>\n",
       "      <td>0.690015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.572797</td>\n",
       "      <td>0.540232</td>\n",
       "      <td>0.720198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.091414</td>\n",
       "      <td>0.570177</td>\n",
       "      <td>0.470744</td>\n",
       "      <td>0.844614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.610739</td>\n",
       "      <td>0.573245</td>\n",
       "      <td>0.694546</td>\n",
       "      <td>0.546191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.785611</td>\n",
       "      <td>0.567309</td>\n",
       "      <td>0.394055</td>\n",
       "      <td>0.871985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.639499</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>0.536212</td>\n",
       "      <td>0.721357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.607838</td>\n",
       "      <td>0.582283</td>\n",
       "      <td>0.591101</td>\n",
       "      <td>0.727285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.623851</td>\n",
       "      <td>0.603516</td>\n",
       "      <td>0.578717</td>\n",
       "      <td>0.677910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.556924</td>\n",
       "      <td>0.662907</td>\n",
       "      <td>0.602682</td>\n",
       "      <td>0.672609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.785362</td>\n",
       "      <td>0.588417</td>\n",
       "      <td>0.494034</td>\n",
       "      <td>0.786930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.658267</td>\n",
       "      <td>0.592360</td>\n",
       "      <td>0.593896</td>\n",
       "      <td>0.680003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.667208</td>\n",
       "      <td>0.587904</td>\n",
       "      <td>0.491653</td>\n",
       "      <td>0.786382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.582900</td>\n",
       "      <td>0.617512</td>\n",
       "      <td>0.586467</td>\n",
       "      <td>0.688635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.663189</td>\n",
       "      <td>0.585994</td>\n",
       "      <td>0.524959</td>\n",
       "      <td>0.712310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.677615</td>\n",
       "      <td>0.604452</td>\n",
       "      <td>0.467671</td>\n",
       "      <td>0.772117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.644598</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>0.489118</td>\n",
       "      <td>0.808042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.648003</td>\n",
       "      <td>0.574566</td>\n",
       "      <td>0.498312</td>\n",
       "      <td>0.820293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.646605</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>0.508664</td>\n",
       "      <td>0.768359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.151120</td>\n",
       "      <td>0.559581</td>\n",
       "      <td>0.488683</td>\n",
       "      <td>0.739501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.630668</td>\n",
       "      <td>0.586219</td>\n",
       "      <td>0.485998</td>\n",
       "      <td>0.775056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.585426</td>\n",
       "      <td>0.533359</td>\n",
       "      <td>0.716443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.613600</td>\n",
       "      <td>0.562050</td>\n",
       "      <td>0.603351</td>\n",
       "      <td>0.683597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.647851</td>\n",
       "      <td>0.566336</td>\n",
       "      <td>0.518559</td>\n",
       "      <td>0.765049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.678203</td>\n",
       "      <td>0.573332</td>\n",
       "      <td>0.602007</td>\n",
       "      <td>0.618839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.868027</td>\n",
       "      <td>0.577915</td>\n",
       "      <td>0.681522</td>\n",
       "      <td>0.693668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.763280</td>\n",
       "      <td>0.565727</td>\n",
       "      <td>0.674572</td>\n",
       "      <td>0.627457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.657572</td>\n",
       "      <td>0.595024</td>\n",
       "      <td>0.596298</td>\n",
       "      <td>0.696256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.599370</td>\n",
       "      <td>0.595469</td>\n",
       "      <td>0.539034</td>\n",
       "      <td>0.717660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.617002</td>\n",
       "      <td>0.569349</td>\n",
       "      <td>0.548773</td>\n",
       "      <td>0.734494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.585511</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.675839</td>\n",
       "      <td>0.519888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.606351</td>\n",
       "      <td>0.577254</td>\n",
       "      <td>0.478862</td>\n",
       "      <td>0.783815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.747134</td>\n",
       "      <td>0.559964</td>\n",
       "      <td>0.464284</td>\n",
       "      <td>0.849087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.636282</td>\n",
       "      <td>0.564538</td>\n",
       "      <td>0.451815</td>\n",
       "      <td>0.807977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.618812</td>\n",
       "      <td>0.572711</td>\n",
       "      <td>0.616493</td>\n",
       "      <td>0.699549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.617504</td>\n",
       "      <td>0.576337</td>\n",
       "      <td>0.541066</td>\n",
       "      <td>0.729338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.600799</td>\n",
       "      <td>0.598071</td>\n",
       "      <td>0.580458</td>\n",
       "      <td>0.683126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.773114</td>\n",
       "      <td>0.565921</td>\n",
       "      <td>0.492039</td>\n",
       "      <td>0.778241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.608421</td>\n",
       "      <td>0.578978</td>\n",
       "      <td>0.575080</td>\n",
       "      <td>0.655597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.609454</td>\n",
       "      <td>0.644180</td>\n",
       "      <td>0.490332</td>\n",
       "      <td>0.693511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss  val_bin_acc      loss   bin_acc\n",
       "0   1.949592     0.545345  0.679174  0.717514\n",
       "1   0.628379     0.615690  0.540690  0.775704\n",
       "2   0.767312     0.611486  0.476352  0.802738\n",
       "3   0.774234     0.594588  0.477878  0.801393\n",
       "4   1.354254     0.556720  0.436396  0.846643\n",
       "5   0.930971     0.562779  0.553420  0.780035\n",
       "6   0.620704     0.601777  0.491871  0.789665\n",
       "7   0.601158     0.628626  0.576487  0.716091\n",
       "8   0.687972     0.592990  0.578266  0.716544\n",
       "9   0.668036     0.604354  0.504097  0.766543\n",
       "10  0.723571     0.691834  0.624880  0.697308\n",
       "11  0.790536     0.590982  0.580731  0.750099\n",
       "12  0.858920     0.562089  0.507616  0.796905\n",
       "13  1.171883     0.671907  0.628383  0.777093\n",
       "14  0.668152     0.580948  0.546803  0.750103\n",
       "15  0.854895     0.664171  0.550152  0.693426\n",
       "16  0.620715     0.590396  0.574091  0.708292\n",
       "17  0.606592     0.610861  0.614475  0.690015\n",
       "18  0.707602     0.572797  0.540232  0.720198\n",
       "19  1.091414     0.570177  0.470744  0.844614\n",
       "20  0.610739     0.573245  0.694546  0.546191\n",
       "21  0.785611     0.567309  0.394055  0.871985\n",
       "22  0.639499     0.600866  0.536212  0.721357\n",
       "23  0.607838     0.582283  0.591101  0.727285\n",
       "24  0.623851     0.603516  0.578717  0.677910\n",
       "25  0.556924     0.662907  0.602682  0.672609\n",
       "26  0.785362     0.588417  0.494034  0.786930\n",
       "27  0.658267     0.592360  0.593896  0.680003\n",
       "28  0.667208     0.587904  0.491653  0.786382\n",
       "29  0.582900     0.617512  0.586467  0.688635\n",
       "30  0.663189     0.585994  0.524959  0.712310\n",
       "31  0.677615     0.604452  0.467671  0.772117\n",
       "32  0.644598     0.571491  0.489118  0.808042\n",
       "33  0.648003     0.574566  0.498312  0.820293\n",
       "34  0.646605     0.567352  0.508664  0.768359\n",
       "35  1.151120     0.559581  0.488683  0.739501\n",
       "36  0.630668     0.586219  0.485998  0.775056\n",
       "37  0.656949     0.585426  0.533359  0.716443\n",
       "38  0.613600     0.562050  0.603351  0.683597\n",
       "39  0.647851     0.566336  0.518559  0.765049\n",
       "40  0.678203     0.573332  0.602007  0.618839\n",
       "41  0.868027     0.577915  0.681522  0.693668\n",
       "42  0.763280     0.565727  0.674572  0.627457\n",
       "43  0.657572     0.595024  0.596298  0.696256\n",
       "44  0.599370     0.595469  0.539034  0.717660\n",
       "45  0.617002     0.569349  0.548773  0.734494\n",
       "46  0.585511     0.661538  0.675839  0.519888\n",
       "47  0.606351     0.577254  0.478862  0.783815\n",
       "48  0.747134     0.559964  0.464284  0.849087\n",
       "49  0.636282     0.564538  0.451815  0.807977\n",
       "50  0.618812     0.572711  0.616493  0.699549\n",
       "51  0.617504     0.576337  0.541066  0.729338\n",
       "52  0.600799     0.598071  0.580458  0.683126\n",
       "53  0.773114     0.565921  0.492039  0.778241\n",
       "54  0.608421     0.578978  0.575080  0.655597\n",
       "55  0.609454     0.644180  0.490332  0.693511"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(data={keys[0]:history[keys[0]], keys[1]:history[keys[1]],\n",
    "                               keys[2]:history[keys[2]], keys[3]:history[keys[3]]})\n",
    "history_df.to_excel('data/tree-rep-profiles_o2o/encEXP_MLP_history_0718.xlsx',index=True)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n",
      "val_loss\n",
      "val_bin_acc\n",
      "loss\n",
      "bin_acc\n",
      "lr\n"
     ]
    }
   ],
   "source": [
    "event_file = log_dir+'events.out.tfevents.1562415044.superpc4'\n",
    "for event in tf.train.summary_iterator(event_file):\n",
    "    for value in event.summary.value:\n",
    "        print(value.tag)\n",
    "        break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.946535050868988\n",
      "bin_acc 0.7701650857925415\n",
      "loss 0.3709505796432495\n",
      "bin_acc 0.8308416604995728\n",
      "loss 0.34396806359291077\n",
      "bin_acc 0.8539522886276245\n",
      "loss 0.3589724004268646\n",
      "bin_acc 0.8503860235214233\n",
      "loss 0.3080110251903534\n",
      "bin_acc 0.8667504787445068\n",
      "loss 0.32501688599586487\n",
      "bin_acc 0.8593385815620422\n",
      "loss 0.31698301434516907\n",
      "bin_acc 0.8747698068618774\n",
      "loss 0.3775538504123688\n",
      "bin_acc 0.8374796509742737\n",
      "loss 0.3339521586894989\n",
      "bin_acc 0.8584908843040466\n",
      "loss 0.32204964756965637\n",
      "bin_acc 0.8647983074188232\n",
      "loss 0.35764580965042114\n",
      "bin_acc 0.8471481800079346\n",
      "loss 0.31919118762016296\n",
      "bin_acc 0.8746025562286377\n",
      "loss 0.3112717270851135\n",
      "bin_acc 0.8738447427749634\n",
      "loss 0.31367820501327515\n",
      "bin_acc 0.865882933139801\n",
      "loss 0.33277350664138794\n",
      "bin_acc 0.858725368976593\n",
      "loss 0.3152080178260803\n",
      "bin_acc 0.8607260584831238\n",
      "loss 0.3059806823730469\n",
      "bin_acc 0.8709530830383301\n",
      "loss 0.33169272541999817\n",
      "bin_acc 0.8512396812438965\n",
      "loss 0.34347817301750183\n",
      "bin_acc 0.8580807447433472\n",
      "loss 0.3191557228565216\n",
      "bin_acc 0.8657838702201843\n",
      "loss 0.31759464740753174\n",
      "bin_acc 0.8698654174804688\n",
      "loss 0.2902257442474365\n",
      "bin_acc 0.8754172921180725\n",
      "loss 0.3000830113887787\n",
      "bin_acc 0.8714452385902405\n",
      "loss 0.3062581419944763\n",
      "bin_acc 0.8715881109237671\n",
      "loss 0.2852591574192047\n",
      "bin_acc 0.8787992000579834\n",
      "loss 0.30855557322502136\n",
      "bin_acc 0.8691225051879883\n",
      "loss 0.3209381401538849\n",
      "bin_acc 0.8685798645019531\n",
      "loss 0.2926829159259796\n",
      "bin_acc 0.8792517781257629\n",
      "loss 0.28573641180992126\n",
      "bin_acc 0.8797064423561096\n",
      "loss 0.26926490664482117\n",
      "bin_acc 0.8895305395126343\n",
      "loss 0.2884407341480255\n",
      "bin_acc 0.875733494758606\n",
      "loss 0.33776456117630005\n",
      "bin_acc 0.8527063131332397\n",
      "loss 0.29692187905311584\n",
      "bin_acc 0.8729410767555237\n",
      "loss 0.23725730180740356\n",
      "bin_acc 0.903010368347168\n",
      "loss 0.2833932042121887\n",
      "bin_acc 0.8775104284286499\n",
      "loss 0.2870582044124603\n",
      "bin_acc 0.8885245323181152\n",
      "loss 0.25726887583732605\n",
      "bin_acc 0.897711455821991\n",
      "loss 0.2742798924446106\n",
      "bin_acc 0.8923629522323608\n",
      "loss 0.3104558289051056\n",
      "bin_acc 0.8744474649429321\n",
      "loss 0.31537705659866333\n",
      "bin_acc 0.8717068433761597\n",
      "loss 0.32085880637168884\n",
      "bin_acc 0.8681702613830566\n",
      "loss 0.3006872832775116\n",
      "bin_acc 0.8739861845970154\n",
      "loss 0.31538882851600647\n",
      "bin_acc 0.8646667003631592\n",
      "loss 0.28410589694976807\n",
      "bin_acc 0.8832449913024902\n",
      "loss 0.28391575813293457\n",
      "bin_acc 0.8795347809791565\n",
      "loss 0.27788934111595154\n",
      "bin_acc 0.8817626237869263\n",
      "loss 0.2998295724391937\n",
      "bin_acc 0.87229984998703\n",
      "loss 0.2689455449581146\n",
      "bin_acc 0.8905202150344849\n",
      "loss 0.2629120945930481\n",
      "bin_acc 0.8926006555557251\n",
      "loss 0.3034431040287018\n",
      "bin_acc 0.8713281750679016\n",
      "loss 0.2525866627693176\n",
      "bin_acc 0.8986326456069946\n",
      "loss 0.29361093044281006\n",
      "bin_acc 0.8795018196105957\n",
      "loss 0.28798815608024597\n",
      "bin_acc 0.8760790228843689\n",
      "loss 0.2813341021537781\n",
      "bin_acc 0.8876785635948181\n",
      "loss 0.28224074840545654\n",
      "bin_acc 0.884327232837677\n",
      "loss 0.3029821515083313\n",
      "bin_acc 0.8725990653038025\n",
      "loss 0.3291667401790619\n",
      "bin_acc 0.866359531879425\n",
      "loss 0.2837073504924774\n",
      "bin_acc 0.8859228491783142\n",
      "loss 0.28247570991516113\n",
      "bin_acc 0.883732259273529\n",
      "loss 0.2772740423679352\n",
      "bin_acc 0.8884140849113464\n",
      "loss 0.2878405451774597\n",
      "bin_acc 0.883294403553009\n",
      "loss 0.2991093695163727\n",
      "bin_acc 0.8758816719055176\n",
      "loss 0.3016839325428009\n",
      "bin_acc 0.8698326945304871\n",
      "loss 0.2698347270488739\n",
      "bin_acc 0.8930387496948242\n",
      "loss 0.2621538043022156\n",
      "bin_acc 0.8968214392662048\n",
      "loss 0.26125192642211914\n",
      "bin_acc 0.8946236371994019\n",
      "loss 0.3253324627876282\n",
      "bin_acc 0.8666625618934631\n",
      "loss 0.2688378393650055\n",
      "bin_acc 0.8839439749717712\n",
      "loss 0.2944672405719757\n",
      "bin_acc 0.8802440762519836\n",
      "loss 0.2886691689491272\n",
      "bin_acc 0.8780438899993896\n",
      "loss 0.323914110660553\n",
      "bin_acc 0.853710412979126\n",
      "loss 0.25309035181999207\n",
      "bin_acc 0.8975832462310791\n",
      "loss 0.2695333957672119\n",
      "bin_acc 0.8926247954368591\n",
      "loss 0.30802133679389954\n",
      "bin_acc 0.864920973777771\n",
      "loss 0.2805185914039612\n",
      "bin_acc 0.8797174096107483\n",
      "loss 0.26536208391189575\n",
      "bin_acc 0.8864395022392273\n",
      "loss 0.2656414210796356\n",
      "bin_acc 0.8902188539505005\n",
      "loss 0.3186369836330414\n",
      "bin_acc 0.864414632320404\n",
      "loss 0.264204204082489\n",
      "bin_acc 0.8906999230384827\n",
      "loss 0.3107571601867676\n",
      "bin_acc 0.8729669451713562\n",
      "loss 0.31000733375549316\n",
      "bin_acc 0.8677937984466553\n",
      "loss 0.2612905204296112\n",
      "bin_acc 0.8920429348945618\n",
      "loss 0.27466872334480286\n",
      "bin_acc 0.8794301152229309\n",
      "loss 0.272781640291214\n",
      "bin_acc 0.8888607025146484\n",
      "loss 0.30116578936576843\n",
      "bin_acc 0.8763347864151001\n",
      "loss 0.2598351240158081\n",
      "bin_acc 0.8931012153625488\n",
      "loss 0.3020326793193817\n",
      "bin_acc 0.870673418045044\n",
      "loss 0.25448793172836304\n",
      "bin_acc 0.8976463079452515\n",
      "loss 0.28808820247650146\n",
      "bin_acc 0.8844919204711914\n",
      "loss 0.2775069773197174\n",
      "bin_acc 0.8855444192886353\n",
      "loss 0.2837279438972473\n",
      "bin_acc 0.8719973564147949\n",
      "loss 0.30402442812919617\n",
      "bin_acc 0.8727828860282898\n",
      "loss 0.30012187361717224\n",
      "bin_acc 0.8675289750099182\n",
      "loss 0.30211910605430603\n",
      "bin_acc 0.868362545967102\n",
      "loss 0.2846076190471649\n",
      "bin_acc 0.8767446279525757\n",
      "loss 0.3143990635871887\n",
      "bin_acc 0.86699378490448\n",
      "loss 0.3062300980091095\n",
      "bin_acc 0.8707791566848755\n",
      "loss 0.3158845603466034\n",
      "bin_acc 0.8598124384880066\n",
      "loss 0.27729204297065735\n",
      "bin_acc 0.8800665140151978\n",
      "loss 0.2770165205001831\n",
      "bin_acc 0.8849910497665405\n",
      "loss 0.26219913363456726\n",
      "bin_acc 0.8960342407226562\n",
      "loss 0.28845036029815674\n",
      "bin_acc 0.8795732855796814\n",
      "loss 0.27147799730300903\n",
      "bin_acc 0.8892977833747864\n",
      "loss 0.27654558420181274\n",
      "bin_acc 0.8799823522567749\n",
      "loss 0.32255423069000244\n",
      "bin_acc 0.8524112105369568\n",
      "loss 0.3113917112350464\n",
      "bin_acc 0.8757935166358948\n",
      "loss 0.2579590380191803\n",
      "bin_acc 0.9019595384597778\n",
      "loss 0.2462085634469986\n",
      "bin_acc 0.8961124420166016\n",
      "loss 0.2937335669994354\n",
      "bin_acc 0.8741627931594849\n",
      "loss 0.26324591040611267\n",
      "bin_acc 0.8857583403587341\n",
      "loss 0.2811414897441864\n",
      "bin_acc 0.8766552209854126\n",
      "loss 0.2938156723976135\n",
      "bin_acc 0.8837200403213501\n",
      "loss 0.24601805210113525\n",
      "bin_acc 0.8993657827377319\n",
      "loss 0.28211531043052673\n",
      "bin_acc 0.8834916949272156\n",
      "loss 0.29630184173583984\n",
      "bin_acc 0.8665380477905273\n",
      "loss 0.27250027656555176\n",
      "bin_acc 0.8835194706916809\n",
      "loss 0.30388742685317993\n",
      "bin_acc 0.8699463605880737\n",
      "loss 0.32802850008010864\n",
      "bin_acc 0.8617929816246033\n",
      "loss 0.27231135964393616\n",
      "bin_acc 0.8928634524345398\n",
      "loss 0.3328302204608917\n",
      "bin_acc 0.8538691401481628\n",
      "loss 0.27610912919044495\n",
      "bin_acc 0.8897938132286072\n",
      "loss 0.2632882595062256\n",
      "bin_acc 0.8876236081123352\n",
      "loss 0.28648242354393005\n",
      "bin_acc 0.879459023475647\n",
      "loss 0.2686770558357239\n",
      "bin_acc 0.8852788805961609\n",
      "loss 0.2635493576526642\n",
      "bin_acc 0.8877083659172058\n",
      "loss 0.2759716808795929\n",
      "bin_acc 0.8882729411125183\n",
      "loss 0.29742884635925293\n",
      "bin_acc 0.8782526254653931\n",
      "loss 0.2666689157485962\n",
      "bin_acc 0.8883077502250671\n",
      "loss 0.2719118297100067\n",
      "bin_acc 0.8812645077705383\n",
      "loss 0.27301207184791565\n",
      "bin_acc 0.8884034156799316\n",
      "loss 0.26701077818870544\n",
      "bin_acc 0.8906735777854919\n",
      "loss 0.2850046157836914\n",
      "bin_acc 0.8756987452507019\n",
      "loss 0.2471241056919098\n",
      "bin_acc 0.9037665128707886\n",
      "loss 0.2878332734107971\n",
      "bin_acc 0.8768686056137085\n",
      "loss 0.2863328456878662\n",
      "bin_acc 0.8770081400871277\n",
      "loss 0.2986944019794464\n",
      "bin_acc 0.8807103633880615\n",
      "loss 0.26337966322898865\n",
      "bin_acc 0.8969902992248535\n",
      "loss 0.29713013768196106\n",
      "bin_acc 0.881047248840332\n",
      "loss 0.30901145935058594\n",
      "bin_acc 0.8749746680259705\n",
      "loss 0.26706409454345703\n",
      "bin_acc 0.8882851600646973\n"
     ]
    }
   ],
   "source": [
    "# e，即event，代表某一個batch的日誌記錄\n",
    "for e in tf.train.summary_iterator(event_file):\n",
    "    # v，即value，代表這個batch的某個已記錄的觀測值，loss或者accuracy\n",
    "    for v in e.summary.value:\n",
    "        if v.tag == 'loss' or v.tag == 'bin_acc':\n",
    "            print(v.tag,v.simple_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
