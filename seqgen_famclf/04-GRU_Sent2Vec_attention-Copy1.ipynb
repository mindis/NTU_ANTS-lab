{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/home/leoqaz12/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os,shutil,pickle,tqdm,sys,random,re,string,pause, datetime,glob\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# # The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\" \n",
    "import keras\n",
    "import sent2vec\n",
    "import seq2seq\n",
    "from seq2seq.models import AttentionSeq2Seq\n",
    "from seq2seq.models import Seq2Seq\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils import *\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras import *\n",
    "from keras.engine.topology import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import *\n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import *\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.cluster import *\n",
    "from sklearn.metrics.pairwise import *\n",
    "\n",
    "# from collections import Counter\n",
    "from keras.utils.generic_utils import *\n",
    "from keras import regularizers\n",
    "import unicodedata as udata\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "from keras import backend \n",
    "from imblearn.ensemble import *\n",
    "from imblearn.combine import *\n",
    "# from python.keras import backend \n",
    "# Embedding(10,20)\n",
    "from keras_transformer.extras import ReusableEmbedding, TiedOutputEmbedding\n",
    "from keras_transformer.position import TransformerCoordinateEmbedding\n",
    "from keras_transformer.transformer import TransformerACT, TransformerBlock\n",
    "from keras_transformer.bert import (\n",
    "    BatchGeneratorForBERT, masked_perplexity,\n",
    "    MaskedPenalizedSparseCategoricalCrossentropy)\n",
    "\n",
    "import keras_metrics as km\n",
    "from keras_trans_mask import RemoveMask, RestoreMask\n",
    "\n",
    "from keras_multi_head import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import transformer_bert_model\n",
    "from bpe import BPEEncoder\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of sent2vec vector: (424, 213, 768) (424, 213) (424, 44) (424, 213, 1)\n"
     ]
    }
   ],
   "source": [
    "train_emb, train_emb_api, train_fam_ans, train_rep_ans = pickle.load(open('data/tree-rep-profiles-partial/TRAIN_sent2vec_vec.pkl','rb'))\n",
    "valid_emb, valid_emb_api,valid_fam_ans,valid_rep_ans = pickle.load(open('data/tree-rep-profiles-partial/DEV_sent2vec_vec.pkl','rb'))\n",
    "test_emb, test_emb_api,test_fam_ans,test_rep_ans = pickle.load(open('data/tree-rep-profiles-partial/TEST_sent2vec_vec.pkl','rb'))\n",
    "# print('train of sent2vec vector:',train_emb.shape,train_emb_api.shape,train_fam_ans.shape,train_rep_ans.shape)\n",
    "# print('valid of sent2vec vector:',valid_emb.shape,valid_emb_api.shape,valid_fam_ans.shape,valid_rep_ans.shape)\n",
    "train_rep_ans = np.expand_dims(train_rep_ans,axis=-1)\n",
    "valid_rep_ans = np.expand_dims(valid_rep_ans,axis=-1)\n",
    "test_rep_ans = np.expand_dims(test_rep_ans,axis=-1)\n",
    "print('test of sent2vec vector:',test_emb.shape,test_emb_api.shape,test_fam_ans.shape,test_rep_ans.shape)\n",
    "emb_matrix = pickle.load(open('data/tree-rep-profiles-partial/api_emb_matrix.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train only fam hash unique\n",
    "def unique_hash(train_emb,train_emb_api,train_fam_ans,train_rep_ans):\n",
    "    unique , indx = np.unique(train_emb, axis=0, return_index=True)\n",
    "    emb_api = train_emb_api[indx]\n",
    "    fam = train_fam_ans[indx]\n",
    "    rep = train_rep_ans[indx]\n",
    "    print(unique.shape,emb_api.shape,fam.shape)\n",
    "    return unique,emb_api,fam,rep #改\n",
    "# train_emb,train_emb_api,train_fam_ans,train_rep_ans = unique_hash(train_emb,train_emb_api,train_fam_ans,train_rep_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle(X, X2 ,X3,X4):\n",
    "#     X3 = np.take(train_fam_ans,[0],axis=-1) #只train第幾個familiy\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "#     print(X.shape, Y.shape)\n",
    "    return (X[randomize], X2[randomize],X3[randomize],X4[randomize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train of sent2vec vector: (11141, 213, 768) (11141, 213) (11141, 44) (11141, 213, 1)\n",
      "valid of sent2vec vector: (437, 213, 768) (437, 213) (437, 44) (437, 213, 1)\n"
     ]
    }
   ],
   "source": [
    "train_emb, train_emb_api, train_fam_ans, train_rep_ans = _shuffle(train_emb, train_emb_api, train_fam_ans, train_rep_ans)\n",
    "valid_emb, valid_emb_api,valid_fam_ans,valid_rep_ans = _shuffle(valid_emb, valid_emb_api,valid_fam_ans,valid_rep_ans)\n",
    "\n",
    "# test_emb, test_emb_api,test_fam_ans,test_rep_ans  = _shuffle(test_emb,test_emb_api,test_fam_ans,test_rep_ans)\n",
    "\n",
    "print('train of sent2vec vector:',train_emb.shape,train_emb_api.shape,train_fam_ans.shape,train_rep_ans.shape)\n",
    "print('valid of sent2vec vector:',valid_emb.shape,valid_emb_api.shape,valid_fam_ans.shape,valid_rep_ans.shape)\n",
    "\n",
    "# print('test of sent2vec vector:',test_emb.shape,test_emb_api.shape,test_fam_ans.shape,test_rep_ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2998, 4344, 1326,  867,  294,  234,  300,  141,  264,  272,  100,\n",
       "        202,  202,   58,   76,  586,   74,   70,   97,   65,   76,  103,\n",
       "        441,   69,   90,  114,   90,   44,   67,   58,  229,   42,   78,\n",
       "         91,  151,  157,   41,   99,   20,   24,   38,   47,   30,  112])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_fam_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kk = np.mean(train_emb,axis=-1)\n",
    "# kk = np.mean(kk,axis=0)\n",
    "# kk = np.expand_dims(kk,axis=0)\n",
    "# kk = np.repeat(kk,100,axis=0)\n",
    "# kk = np.expand_dims(kk,axis=-1)\n",
    "# kk = np.repeat(kk,768,axis=-1)\n",
    "# kk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kkk = (emb_matrix - kk)/kk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kk = np.std(emb_matrix,axis=-1)\n",
    "# kk = np.expand_dims(kk,axis=-1)\n",
    "# kk = np.repeat(kk,768,axis=-1)\n",
    "# kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bc = SMOTEENN()\n",
    "# N,t,d = train_emb.shape\n",
    "# train_emb_ = train_emb.reshape(N,t*d)\n",
    "# train_fam_ans_ = train_fam_ans.reshape(N,)\n",
    "# train_emb_ , train_fam_ans_  = bc.fit_resample(train_emb_, train_fam_ans_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_emb = train_emb_.reshape(-1,t,d)\n",
    "# train_fam_ans = train_fam_ans_.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0043028310118869,\n",
       " 1: 1.0,\n",
       " 2: 1.8200813389286221,\n",
       " 3: 2.244964532893888,\n",
       " 4: 3.326423742335748,\n",
       " 5: 3.5546823943167287,\n",
       " 6: 3.306221035018229,\n",
       " 7: 4.0612436192962615,\n",
       " 8: 3.434054406528114,\n",
       " 9: 3.4042014433784327,\n",
       " 10: 4.404833323686339,\n",
       " 11: 3.7017358122732253,\n",
       " 12: 3.7017358122732253,\n",
       " 13: 4.949560499128011,\n",
       " 14: 4.679270169388099,\n",
       " 15: 2.6366837200974174,\n",
       " 16: 4.705938416470261,\n",
       " 17: 4.761508267625071,\n",
       " 18: 4.435292531171047,\n",
       " 19: 4.835616239778793,\n",
       " 20: 4.679270169388099,\n",
       " 21: 4.375274521444794,\n",
       " 22: 2.920958634227584,\n",
       " 23: 4.77589700507717,\n",
       " 24: 4.510193839344165,\n",
       " 25: 4.273805061279934,\n",
       " 26: 4.510193839344165,\n",
       " 27: 5.2258138757561685,\n",
       " 28: 4.805310890283464,\n",
       " 29: 4.949560499128011,\n",
       " 30: 3.5762815061201905,\n",
       " 31: 5.272333891391061,\n",
       " 32: 4.653294682984838,\n",
       " 33: 4.49914400315758,\n",
       " 34: 3.9927236728595057,\n",
       " 35: 3.953757704326122,\n",
       " 36: 5.296431442970122,\n",
       " 37: 4.41488365953984,\n",
       " 38: 6.014271236120439,\n",
       " 39: 5.831949679326485,\n",
       " 40: 5.372417349948044,\n",
       " 41: 5.1598559079643715,\n",
       " 42: 5.608806128012275,\n",
       " 43: 4.291504638379336}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = sum(train_fam_ans) / sum(sum(train_fam_ans))\n",
    "fam_weights={}\n",
    "for i in range(len(class_weights)):\n",
    "    fam_weights[i] = 1/class_weights[i]\n",
    "fam_weights\n",
    "\n",
    "all_fam = sum(train_fam_ans)\n",
    "for i in range(len(all_fam)):\n",
    "    fam_weights[i] = all_fam[i]\n",
    "fam_weights\n",
    "\n",
    "import math\n",
    "def create_class_weight(labels_dict,mu=0.55): #0.79 #0.5: only hash #改 #0.55: not only hash\n",
    "    total = np.sum(np.array(list(labels_dict.values())))\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "\n",
    "    for key in keys:\n",
    "        score = math.log(mu*total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "fam_weights = create_class_weight(fam_weights)\n",
    "fam_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fam_weight = {}\n",
    "fam_weight['family'] = fam_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 768 #被除數\n",
    "num_heads = 48#除數，要整除\n",
    "max_length = 213 # max sequence length\n",
    "fam_num = train_fam_ans.shape[1]\n",
    "vocabulary_size = 26\n",
    "transformer_depth = 1\n",
    "transformer_dropout = 0.1\n",
    "l2_reg_penalty = 1e-6#1e-4\n",
    "dp_rate = 0.2\n",
    "\n",
    "traina = True #改\n",
    "batch_size = 128 #改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrain = keras.constraints.MinMaxNorm(min_value=0.0, max_value=0.0, rate=1.0, axis=0)\n",
    "init = keras.initializers.Ones()\n",
    "coordinate_embedding_layer = TransformerCoordinateEmbedding(\n",
    "        transformer_depth , name='coordinate_embedding')\n",
    "act_layer = TransformerACT(\n",
    "            name='adaptive_computation_time')\n",
    "\n",
    "transformer_block = TransformerBlock(\n",
    "            name='transformer', num_heads=num_heads,\n",
    "            residual_dropout=transformer_dropout,\n",
    "            attention_dropout=transformer_dropout,\n",
    "            # Allow bi-directional attention\n",
    "            use_masking=False)\n",
    "add_segment_layer = Add(name='add_segment')\n",
    "l2_regularizer = (regularizers.l2(l2_reg_penalty) if l2_reg_penalty else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentemb1 = Input(shape=(max_length,emb_dim),name='sent_emb')\n",
    "sentemb = Masking(mask_value=0)(sentemb1)\n",
    "#shape=(max_length,emb_dim),,batch_shape=(batch_size,max_length,emb_dim)\n",
    "sent_ids1 = Input(shape=(max_length,), dtype='int32', name='sent_ids') # 輸入的api funvtion name ID\n",
    "sent_ids = Masking(mask_value=0)(sent_ids1)\n",
    "#shape=(max_length,),batch_shape=(batch_size,max_length)\n",
    "api_emb = Embedding(vocabulary_size+1, emb_dim,weights=[emb_matrix],input_length=max_length\n",
    "                    ,trainable=True,name='api_emb')(sent_ids) #改\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment_embeddings = Add()([sentemb,api_emb])\n",
    "# next_step_input1 = RemoveMask()(segment_embeddings)\n",
    "# next_step_input = coordinate_embedding_layer(next_step_input1, step=0,trainable=traina) #next_step_input_emb\n",
    "# next_step_input= RestoreMask()([next_step_input,segment_embeddings])\n",
    "# next_step_input = add_segment_layer([next_step_input, api_emb]) \n",
    "\n",
    "att_rnn,state_h,state_c = LSTM(int(emb_dim/4),return_sequences=True,return_state=True,name='common_extract'\n",
    "                      ,trainable=True)(segment_embeddings)\n",
    "state = Concatenate()([state_h,state_c])\n",
    "state = BatchNormalization(name = 'bn_in')(state)\n",
    "\n",
    "expand = Lambda(lambda x: keras.backend.expand_dims(x,axis=-1))\n",
    "all_rep = []\n",
    "for i in range(fam_num):\n",
    "    all_rep.append(\n",
    "    Dense(1,activation='sigmoid',name='out_'+str(i))\n",
    "    (Dense(32,kernel_initializer='lecun_normal',activation='selu',name='in_'+str(i))\n",
    "    (BatchNormalization(name='bn_'+str(i))\n",
    "     (Dropout(dp_rate)\n",
    "    (GRU(96,kernel_initializer='lecun_normal')\n",
    "    (Multiply()([Lambda(lambda x: keras.backend.expand_dims(x,axis=-1))(Dense(213 \n",
    "                                                                              ,kernel_initializer='lecun_normal'\n",
    "                                                                              ,activation='sigmoid'\n",
    "                                                                             , name = 'family_'+str(i))(state))\n",
    "                 ,att_rnn]))\n",
    "    )))))\n",
    "    \n",
    "out = Concatenate(name='family')(all_rep)\n",
    "# next_step_input = BatchNormalization(name='bn_commo')(att_rnn)\n",
    "# att_in = TimeDistributed(Dense(64,kernel_initializer=keras.initializers.lecun_normal(),activation='selu', # 改\n",
    "#                name='attention_mlp',trainable=False),name='in_rep')(next_step_input)\n",
    "# rep_prediction = (\n",
    "#         TimeDistributed(Dense(1, name='0_1_predict', activation='sigmoid',trainable=False),name='out_rep') # hard_sigmoid\n",
    "#     (att_in))\n",
    "\n",
    "# state = Concatenate()([state_h,state_c])\n",
    "\n",
    "# bn = BatchNormalization(name='bn_state')(state)\n",
    "# state = Dense(int(emb_dim/32),kernel_initializer=keras.initializers.lecun_normal(),activation='selu')(bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"att_layer = BatchNormalization(name='bn1')(att_layer)\\nhead_out = MultiHead(Dense(4,kernel_initializer=keras.initializers.lecun_normal(),activation='selu')\\n                     ,layer_num=2,name='Multi-Dense')(att_layer)\\nhead_out1 = RemoveMask()(head_out)\\nflat = Flatten()(head_out1)\\n# flat = RestoreMask()([flat,att_layer])\\ncon = Concatenate()([state_h,state_c])\\nflat = Concatenate()([con,flat])\\nbn = BatchNormalization(name='bn2')(flat)\\ndense2 = Dense(1024,kernel_initializer=keras.initializers.lecun_normal(),activation='selu',\\n              name='dense2')(bn)\\ndp = Dropout(dp_rate)(dense2)\\nout = Dense(44,activation='sigmoid',name='family_out')(dp)\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# mul = multiply([segment_embeddings,rep_prediction],name='mul')\n",
    "# # mul = BatchNormalization()(mul)\n",
    "# att_layer = MultiHeadAttention(\n",
    "#     head_num=4, trainable=True,\n",
    "#     name='Multi-Head')(mul)\n",
    "\n",
    "\n",
    "# lstm,state_h,state_c = LSTM(int(emb_dim/2),return_sequences=False,return_state=True,name='family_in')(att_layer)\n",
    "\n",
    "# state = Concatenate()([state_h_g,state_c])\n",
    "# state = Dense(16,activation='elu')(state)\n",
    "\n",
    "# alls=[]\n",
    "# for i in range(fam_num):\n",
    "#     alls.append(Dense(1,activation='sigmoid') \n",
    "#                 (Dense(32,kernel_initializer=keras.initializers.lecun_normal(),activation='selu')\n",
    "#                  (BatchNormalization() (Concatenate()([Dropout(dp_rate)\n",
    "#                                                        (Dense(128\n",
    "#                                                               ,kernel_initializer=keras.initializers.lecun_normal()\n",
    "#                                                               ,activation='selu')(BatchNormalization()(lstm))\n",
    "#                                                        ),state])))))\n",
    "#                      (Dropout(dp_rate)\n",
    "#                 (Dense(128,kernel_initializer=keras.initializers.lecun_normal(),activation='selu')\n",
    "#                  (BatchNormalization()\n",
    "#                   (lstm)\n",
    "#                   ))))))\n",
    "# out = Concatenate(name='family')(alls)\n",
    "\n",
    "\n",
    "'''att_layer = BatchNormalization(name='bn1')(att_layer)\n",
    "head_out = MultiHead(Dense(4,kernel_initializer=keras.initializers.lecun_normal(),activation='selu')\n",
    "                     ,layer_num=2,name='Multi-Dense')(att_layer)\n",
    "head_out1 = RemoveMask()(head_out)\n",
    "flat = Flatten()(head_out1)\n",
    "# flat = RestoreMask()([flat,att_layer])\n",
    "con = Concatenate()([state_h,state_c])\n",
    "flat = Concatenate()([con,flat])\n",
    "bn = BatchNormalization(name='bn2')(flat)\n",
    "dense2 = Dense(1024,kernel_initializer=keras.initializers.lecun_normal(),activation='selu',\n",
    "              name='dense2')(bn)\n",
    "dp = Dropout(dp_rate)(dense2)\n",
    "out = Dense(44,activation='sigmoid',name='family_out')(dp)'''\n",
    "                     \n",
    "# bn = BatchNormalization()\n",
    "# dp = Dropout(dp_rate)\n",
    "# dense1 = Dense(int(emb_dim/8),kernel_initializer=keras.initializers.lecun_normal(),activation='selu',\n",
    "#               kernel_regularizer=l2_regularizer,name='dense1')\n",
    "# dense2 = Dense(32,kernel_initializer=keras.initializers.lecun_normal(),activation='selu',\n",
    "#               name='dense2')\n",
    "# dense3 = Dense(1,kernel_initializer=keras.initializers.lecun_normal(),activation='sigmoid',\n",
    "#               name='dense3')\n",
    "# gru = GRU(int(emb_dim/4), dropout=dp_rate, recurrent_dropout=dp_rate,name='gru_64')\n",
    "# alls = []\n",
    "# for i in range(fam_num):\n",
    "#     alls.append(dense2(bn(gru(mul))))\n",
    "# #     alls.append(dense3(dense2(dp(bn(dense1(BatchNormalization()(gru(mul))))))))\n",
    "# out = Concatenate()(alls)\n",
    "# out = BatchNormalization()(out)\n",
    "# bn = BatchNormalization()\n",
    "# all_out = []\n",
    "# for i in range(fam_num):\n",
    "#     all_out.append(dense3(bn(dense1(out))))\n",
    "# out1 = Concatenate()(all_out)\n",
    "# # out = Dense(44,activation='sigmoid',name='family_out')(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sent_ids (InputLayer)           (None, 213)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sent_emb (InputLayer)           (None, 213, 768)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_6 (Masking)             (None, 213)          0           sent_ids[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "masking_5 (Masking)             (None, 213, 768)     0           sent_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "api_emb (Embedding)             (None, 213, 768)     20736       masking_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 213, 768)     0           masking_5[0][0]                  \n",
      "                                                                 api_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "common_extract (LSTM)           [(None, 213, 192), ( 738048      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 384)          0           common_extract[0][1]             \n",
      "                                                                 common_extract[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_in (BatchNormalization)      (None, 384)          1536        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "family_0 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_1 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_2 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_3 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_4 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_5 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_6 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_7 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_8 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_9 (Dense)                (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_10 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_11 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_12 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_13 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_14 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_15 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_16 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_17 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_18 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_19 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_20 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_21 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_22 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_23 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_24 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_25 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_26 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_27 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_28 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_29 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_30 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_31 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_32 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_33 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_34 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_35 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_36 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_37 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_38 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_39 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_40 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_41 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_42 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family_43 (Dense)               (None, 213)          82005       bn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)             (None, 213, 1)       0           family_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)             (None, 213, 1)       0           family_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_139 (Lambda)             (None, 213, 1)       0           family_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_140 (Lambda)             (None, 213, 1)       0           family_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)             (None, 213, 1)       0           family_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_142 (Lambda)             (None, 213, 1)       0           family_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_143 (Lambda)             (None, 213, 1)       0           family_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_144 (Lambda)             (None, 213, 1)       0           family_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_145 (Lambda)             (None, 213, 1)       0           family_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)             (None, 213, 1)       0           family_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_147 (Lambda)             (None, 213, 1)       0           family_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_148 (Lambda)             (None, 213, 1)       0           family_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_149 (Lambda)             (None, 213, 1)       0           family_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_150 (Lambda)             (None, 213, 1)       0           family_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)             (None, 213, 1)       0           family_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)             (None, 213, 1)       0           family_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)             (None, 213, 1)       0           family_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)             (None, 213, 1)       0           family_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_155 (Lambda)             (None, 213, 1)       0           family_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)             (None, 213, 1)       0           family_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_157 (Lambda)             (None, 213, 1)       0           family_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_158 (Lambda)             (None, 213, 1)       0           family_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_159 (Lambda)             (None, 213, 1)       0           family_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_160 (Lambda)             (None, 213, 1)       0           family_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_161 (Lambda)             (None, 213, 1)       0           family_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_162 (Lambda)             (None, 213, 1)       0           family_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_163 (Lambda)             (None, 213, 1)       0           family_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_164 (Lambda)             (None, 213, 1)       0           family_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_165 (Lambda)             (None, 213, 1)       0           family_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_166 (Lambda)             (None, 213, 1)       0           family_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_167 (Lambda)             (None, 213, 1)       0           family_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_168 (Lambda)             (None, 213, 1)       0           family_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_169 (Lambda)             (None, 213, 1)       0           family_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_170 (Lambda)             (None, 213, 1)       0           family_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_171 (Lambda)             (None, 213, 1)       0           family_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_172 (Lambda)             (None, 213, 1)       0           family_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_173 (Lambda)             (None, 213, 1)       0           family_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_174 (Lambda)             (None, 213, 1)       0           family_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_175 (Lambda)             (None, 213, 1)       0           family_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_176 (Lambda)             (None, 213, 1)       0           family_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_177 (Lambda)             (None, 213, 1)       0           family_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_178 (Lambda)             (None, 213, 1)       0           family_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_179 (Lambda)             (None, 213, 1)       0           family_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_180 (Lambda)             (None, 213, 1)       0           family_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_133 (Multiply)         (None, 213, 192)     0           lambda_137[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_134 (Multiply)         (None, 213, 192)     0           lambda_138[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_135 (Multiply)         (None, 213, 192)     0           lambda_139[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_136 (Multiply)         (None, 213, 192)     0           lambda_140[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_137 (Multiply)         (None, 213, 192)     0           lambda_141[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_138 (Multiply)         (None, 213, 192)     0           lambda_142[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_139 (Multiply)         (None, 213, 192)     0           lambda_143[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_140 (Multiply)         (None, 213, 192)     0           lambda_144[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_141 (Multiply)         (None, 213, 192)     0           lambda_145[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_142 (Multiply)         (None, 213, 192)     0           lambda_146[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_143 (Multiply)         (None, 213, 192)     0           lambda_147[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_144 (Multiply)         (None, 213, 192)     0           lambda_148[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_145 (Multiply)         (None, 213, 192)     0           lambda_149[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_146 (Multiply)         (None, 213, 192)     0           lambda_150[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_147 (Multiply)         (None, 213, 192)     0           lambda_151[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_148 (Multiply)         (None, 213, 192)     0           lambda_152[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_149 (Multiply)         (None, 213, 192)     0           lambda_153[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_150 (Multiply)         (None, 213, 192)     0           lambda_154[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_151 (Multiply)         (None, 213, 192)     0           lambda_155[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_152 (Multiply)         (None, 213, 192)     0           lambda_156[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_153 (Multiply)         (None, 213, 192)     0           lambda_157[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_154 (Multiply)         (None, 213, 192)     0           lambda_158[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_155 (Multiply)         (None, 213, 192)     0           lambda_159[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_156 (Multiply)         (None, 213, 192)     0           lambda_160[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_157 (Multiply)         (None, 213, 192)     0           lambda_161[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_158 (Multiply)         (None, 213, 192)     0           lambda_162[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_159 (Multiply)         (None, 213, 192)     0           lambda_163[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_160 (Multiply)         (None, 213, 192)     0           lambda_164[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_161 (Multiply)         (None, 213, 192)     0           lambda_165[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_162 (Multiply)         (None, 213, 192)     0           lambda_166[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_163 (Multiply)         (None, 213, 192)     0           lambda_167[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_164 (Multiply)         (None, 213, 192)     0           lambda_168[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_165 (Multiply)         (None, 213, 192)     0           lambda_169[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_166 (Multiply)         (None, 213, 192)     0           lambda_170[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_167 (Multiply)         (None, 213, 192)     0           lambda_171[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_168 (Multiply)         (None, 213, 192)     0           lambda_172[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_169 (Multiply)         (None, 213, 192)     0           lambda_173[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_170 (Multiply)         (None, 213, 192)     0           lambda_174[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_171 (Multiply)         (None, 213, 192)     0           lambda_175[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_172 (Multiply)         (None, 213, 192)     0           lambda_176[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_173 (Multiply)         (None, 213, 192)     0           lambda_177[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_174 (Multiply)         (None, 213, 192)     0           lambda_178[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_175 (Multiply)         (None, 213, 192)     0           lambda_179[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_176 (Multiply)         (None, 213, 192)     0           lambda_180[0][0]                 \n",
      "                                                                 common_extract[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_133 (GRU)                   (None, 96)           83232       multiply_133[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_134 (GRU)                   (None, 96)           83232       multiply_134[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_135 (GRU)                   (None, 96)           83232       multiply_135[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_136 (GRU)                   (None, 96)           83232       multiply_136[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_137 (GRU)                   (None, 96)           83232       multiply_137[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_138 (GRU)                   (None, 96)           83232       multiply_138[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_139 (GRU)                   (None, 96)           83232       multiply_139[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_140 (GRU)                   (None, 96)           83232       multiply_140[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_141 (GRU)                   (None, 96)           83232       multiply_141[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_142 (GRU)                   (None, 96)           83232       multiply_142[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_143 (GRU)                   (None, 96)           83232       multiply_143[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_144 (GRU)                   (None, 96)           83232       multiply_144[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_145 (GRU)                   (None, 96)           83232       multiply_145[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_146 (GRU)                   (None, 96)           83232       multiply_146[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_147 (GRU)                   (None, 96)           83232       multiply_147[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_148 (GRU)                   (None, 96)           83232       multiply_148[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_149 (GRU)                   (None, 96)           83232       multiply_149[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_150 (GRU)                   (None, 96)           83232       multiply_150[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_151 (GRU)                   (None, 96)           83232       multiply_151[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_152 (GRU)                   (None, 96)           83232       multiply_152[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_153 (GRU)                   (None, 96)           83232       multiply_153[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_154 (GRU)                   (None, 96)           83232       multiply_154[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_155 (GRU)                   (None, 96)           83232       multiply_155[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_156 (GRU)                   (None, 96)           83232       multiply_156[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_157 (GRU)                   (None, 96)           83232       multiply_157[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_158 (GRU)                   (None, 96)           83232       multiply_158[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_159 (GRU)                   (None, 96)           83232       multiply_159[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_160 (GRU)                   (None, 96)           83232       multiply_160[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_161 (GRU)                   (None, 96)           83232       multiply_161[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_162 (GRU)                   (None, 96)           83232       multiply_162[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_163 (GRU)                   (None, 96)           83232       multiply_163[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_164 (GRU)                   (None, 96)           83232       multiply_164[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_165 (GRU)                   (None, 96)           83232       multiply_165[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_166 (GRU)                   (None, 96)           83232       multiply_166[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_167 (GRU)                   (None, 96)           83232       multiply_167[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_168 (GRU)                   (None, 96)           83232       multiply_168[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_169 (GRU)                   (None, 96)           83232       multiply_169[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_170 (GRU)                   (None, 96)           83232       multiply_170[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_171 (GRU)                   (None, 96)           83232       multiply_171[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_172 (GRU)                   (None, 96)           83232       multiply_172[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_173 (GRU)                   (None, 96)           83232       multiply_173[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_174 (GRU)                   (None, 96)           83232       multiply_174[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_175 (GRU)                   (None, 96)           83232       multiply_175[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_176 (GRU)                   (None, 96)           83232       multiply_176[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 96)           0           gru_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 96)           0           gru_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 96)           0           gru_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 96)           0           gru_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 96)           0           gru_137[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 96)           0           gru_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 96)           0           gru_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 96)           0           gru_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 96)           0           gru_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 96)           0           gru_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 96)           0           gru_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 96)           0           gru_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 96)           0           gru_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 96)           0           gru_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 96)           0           gru_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 96)           0           gru_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 96)           0           gru_149[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 96)           0           gru_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 96)           0           gru_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 96)           0           gru_152[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 96)           0           gru_153[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 96)           0           gru_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 96)           0           gru_155[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 96)           0           gru_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 96)           0           gru_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 96)           0           gru_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 96)           0           gru_159[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 96)           0           gru_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 96)           0           gru_161[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 96)           0           gru_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 96)           0           gru_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 96)           0           gru_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 96)           0           gru_165[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, 96)           0           gru_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, 96)           0           gru_167[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 96)           0           gru_168[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 96)           0           gru_169[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 96)           0           gru_170[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 96)           0           gru_171[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 96)           0           gru_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 96)           0           gru_173[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 96)           0           gru_174[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 96)           0           gru_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 96)           0           gru_176[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_0 (BatchNormalization)       (None, 96)           384         dropout_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_1 (BatchNormalization)       (None, 96)           384         dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_2 (BatchNormalization)       (None, 96)           384         dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_3 (BatchNormalization)       (None, 96)           384         dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_4 (BatchNormalization)       (None, 96)           384         dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_5 (BatchNormalization)       (None, 96)           384         dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_6 (BatchNormalization)       (None, 96)           384         dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_7 (BatchNormalization)       (None, 96)           384         dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_8 (BatchNormalization)       (None, 96)           384         dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_9 (BatchNormalization)       (None, 96)           384         dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_10 (BatchNormalization)      (None, 96)           384         dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_11 (BatchNormalization)      (None, 96)           384         dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_12 (BatchNormalization)      (None, 96)           384         dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_13 (BatchNormalization)      (None, 96)           384         dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_14 (BatchNormalization)      (None, 96)           384         dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_15 (BatchNormalization)      (None, 96)           384         dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_16 (BatchNormalization)      (None, 96)           384         dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_17 (BatchNormalization)      (None, 96)           384         dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_18 (BatchNormalization)      (None, 96)           384         dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_19 (BatchNormalization)      (None, 96)           384         dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_20 (BatchNormalization)      (None, 96)           384         dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_21 (BatchNormalization)      (None, 96)           384         dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_22 (BatchNormalization)      (None, 96)           384         dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_23 (BatchNormalization)      (None, 96)           384         dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_24 (BatchNormalization)      (None, 96)           384         dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_25 (BatchNormalization)      (None, 96)           384         dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_26 (BatchNormalization)      (None, 96)           384         dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_27 (BatchNormalization)      (None, 96)           384         dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_28 (BatchNormalization)      (None, 96)           384         dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_29 (BatchNormalization)      (None, 96)           384         dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_30 (BatchNormalization)      (None, 96)           384         dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_31 (BatchNormalization)      (None, 96)           384         dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_32 (BatchNormalization)      (None, 96)           384         dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_33 (BatchNormalization)      (None, 96)           384         dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_34 (BatchNormalization)      (None, 96)           384         dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_35 (BatchNormalization)      (None, 96)           384         dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_36 (BatchNormalization)      (None, 96)           384         dropout_169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_37 (BatchNormalization)      (None, 96)           384         dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_38 (BatchNormalization)      (None, 96)           384         dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_39 (BatchNormalization)      (None, 96)           384         dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_40 (BatchNormalization)      (None, 96)           384         dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_41 (BatchNormalization)      (None, 96)           384         dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_42 (BatchNormalization)      (None, 96)           384         dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_43 (BatchNormalization)      (None, 96)           384         dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "in_0 (Dense)                    (None, 32)           3104        bn_0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_1 (Dense)                    (None, 32)           3104        bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_2 (Dense)                    (None, 32)           3104        bn_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_3 (Dense)                    (None, 32)           3104        bn_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_4 (Dense)                    (None, 32)           3104        bn_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_5 (Dense)                    (None, 32)           3104        bn_5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_6 (Dense)                    (None, 32)           3104        bn_6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_7 (Dense)                    (None, 32)           3104        bn_7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_8 (Dense)                    (None, 32)           3104        bn_8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_9 (Dense)                    (None, 32)           3104        bn_9[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "in_10 (Dense)                   (None, 32)           3104        bn_10[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_11 (Dense)                   (None, 32)           3104        bn_11[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_12 (Dense)                   (None, 32)           3104        bn_12[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_13 (Dense)                   (None, 32)           3104        bn_13[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_14 (Dense)                   (None, 32)           3104        bn_14[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_15 (Dense)                   (None, 32)           3104        bn_15[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_16 (Dense)                   (None, 32)           3104        bn_16[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_17 (Dense)                   (None, 32)           3104        bn_17[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_18 (Dense)                   (None, 32)           3104        bn_18[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_19 (Dense)                   (None, 32)           3104        bn_19[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_20 (Dense)                   (None, 32)           3104        bn_20[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_21 (Dense)                   (None, 32)           3104        bn_21[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_22 (Dense)                   (None, 32)           3104        bn_22[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_23 (Dense)                   (None, 32)           3104        bn_23[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_24 (Dense)                   (None, 32)           3104        bn_24[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_25 (Dense)                   (None, 32)           3104        bn_25[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_26 (Dense)                   (None, 32)           3104        bn_26[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_27 (Dense)                   (None, 32)           3104        bn_27[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_28 (Dense)                   (None, 32)           3104        bn_28[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_29 (Dense)                   (None, 32)           3104        bn_29[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_30 (Dense)                   (None, 32)           3104        bn_30[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_31 (Dense)                   (None, 32)           3104        bn_31[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_32 (Dense)                   (None, 32)           3104        bn_32[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_33 (Dense)                   (None, 32)           3104        bn_33[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_34 (Dense)                   (None, 32)           3104        bn_34[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_35 (Dense)                   (None, 32)           3104        bn_35[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_36 (Dense)                   (None, 32)           3104        bn_36[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_37 (Dense)                   (None, 32)           3104        bn_37[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_38 (Dense)                   (None, 32)           3104        bn_38[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_39 (Dense)                   (None, 32)           3104        bn_39[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_40 (Dense)                   (None, 32)           3104        bn_40[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_41 (Dense)                   (None, 32)           3104        bn_41[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_42 (Dense)                   (None, 32)           3104        bn_42[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_43 (Dense)                   (None, 32)           3104        bn_43[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_0 (Dense)                   (None, 1)            33          in_0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 1)            33          in_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 1)            33          in_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_3 (Dense)                   (None, 1)            33          in_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_4 (Dense)                   (None, 1)            33          in_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_5 (Dense)                   (None, 1)            33          in_5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_6 (Dense)                   (None, 1)            33          in_6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_7 (Dense)                   (None, 1)            33          in_7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_8 (Dense)                   (None, 1)            33          in_8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_9 (Dense)                   (None, 1)            33          in_9[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out_10 (Dense)                  (None, 1)            33          in_10[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_11 (Dense)                  (None, 1)            33          in_11[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_12 (Dense)                  (None, 1)            33          in_12[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_13 (Dense)                  (None, 1)            33          in_13[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_14 (Dense)                  (None, 1)            33          in_14[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_15 (Dense)                  (None, 1)            33          in_15[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_16 (Dense)                  (None, 1)            33          in_16[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_17 (Dense)                  (None, 1)            33          in_17[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_18 (Dense)                  (None, 1)            33          in_18[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_19 (Dense)                  (None, 1)            33          in_19[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_20 (Dense)                  (None, 1)            33          in_20[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_21 (Dense)                  (None, 1)            33          in_21[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_22 (Dense)                  (None, 1)            33          in_22[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_23 (Dense)                  (None, 1)            33          in_23[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_24 (Dense)                  (None, 1)            33          in_24[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_25 (Dense)                  (None, 1)            33          in_25[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_26 (Dense)                  (None, 1)            33          in_26[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_27 (Dense)                  (None, 1)            33          in_27[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_28 (Dense)                  (None, 1)            33          in_28[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_29 (Dense)                  (None, 1)            33          in_29[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_30 (Dense)                  (None, 1)            33          in_30[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_31 (Dense)                  (None, 1)            33          in_31[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_32 (Dense)                  (None, 1)            33          in_32[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_33 (Dense)                  (None, 1)            33          in_33[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_34 (Dense)                  (None, 1)            33          in_34[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_35 (Dense)                  (None, 1)            33          in_35[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_36 (Dense)                  (None, 1)            33          in_36[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_37 (Dense)                  (None, 1)            33          in_37[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_38 (Dense)                  (None, 1)            33          in_38[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_39 (Dense)                  (None, 1)            33          in_39[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_40 (Dense)                  (None, 1)            33          in_40[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_41 (Dense)                  (None, 1)            33          in_41[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_42 (Dense)                  (None, 1)            33          in_42[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_43 (Dense)                  (None, 1)            33          in_43[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "family (Concatenate)            (None, 44)           0           out_0[0][0]                      \n",
      "                                                                 out_1[0][0]                      \n",
      "                                                                 out_2[0][0]                      \n",
      "                                                                 out_3[0][0]                      \n",
      "                                                                 out_4[0][0]                      \n",
      "                                                                 out_5[0][0]                      \n",
      "                                                                 out_6[0][0]                      \n",
      "                                                                 out_7[0][0]                      \n",
      "                                                                 out_8[0][0]                      \n",
      "                                                                 out_9[0][0]                      \n",
      "                                                                 out_10[0][0]                     \n",
      "                                                                 out_11[0][0]                     \n",
      "                                                                 out_12[0][0]                     \n",
      "                                                                 out_13[0][0]                     \n",
      "                                                                 out_14[0][0]                     \n",
      "                                                                 out_15[0][0]                     \n",
      "                                                                 out_16[0][0]                     \n",
      "                                                                 out_17[0][0]                     \n",
      "                                                                 out_18[0][0]                     \n",
      "                                                                 out_19[0][0]                     \n",
      "                                                                 out_20[0][0]                     \n",
      "                                                                 out_21[0][0]                     \n",
      "                                                                 out_22[0][0]                     \n",
      "                                                                 out_23[0][0]                     \n",
      "                                                                 out_24[0][0]                     \n",
      "                                                                 out_25[0][0]                     \n",
      "                                                                 out_26[0][0]                     \n",
      "                                                                 out_27[0][0]                     \n",
      "                                                                 out_28[0][0]                     \n",
      "                                                                 out_29[0][0]                     \n",
      "                                                                 out_30[0][0]                     \n",
      "                                                                 out_31[0][0]                     \n",
      "                                                                 out_32[0][0]                     \n",
      "                                                                 out_33[0][0]                     \n",
      "                                                                 out_34[0][0]                     \n",
      "                                                                 out_35[0][0]                     \n",
      "                                                                 out_36[0][0]                     \n",
      "                                                                 out_37[0][0]                     \n",
      "                                                                 out_38[0][0]                     \n",
      "                                                                 out_39[0][0]                     \n",
      "                                                                 out_40[0][0]                     \n",
      "                                                                 out_41[0][0]                     \n",
      "                                                                 out_42[0][0]                     \n",
      "                                                                 out_43[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,185,672\n",
      "Trainable params: 8,176,456\n",
      "Non-trainable params: 9,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[sent_ids1,sentemb1], outputs=[out]) #out\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model/att_clf/2ndStage_44fam_0616_gru_sent2vec.h5',by_name=True) #改\n",
    "model = multi_gpu_model(model , gpus=2)\n",
    "\n",
    "# model.load_weights('./model/LSTM_att/1stStage_44fam_0607.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nsentemb1 = Input(shape=(max_length,emb_dim),name='sent_emb')\\nsentemb = Masking(mask_value=0)(sentemb1)\\nsent_ids1 = Input(shape=(max_length,), dtype='int32', name='sent_ids') # 輸入的api funvtion name ID\\nsent_ids = Masking(mask_value=0)(sent_ids1)\\napi_emb = Embedding(vocabulary_size+1, emb_dim,weights=[emb_matrix],input_length=max_length,trainable=True,name='api_emb')(sent_ids)\\n\\nfinal_emb = Add()([sentemb,api_emb])\\n\\ntimesteps,state_h,state_c = LSTM(int(emb_dim/2),return_sequences=True,return_state=True,name='lstm1')(final_emb) #final_emb\\nstate = Concatenate()([state_h,state_c])\\nfc = Dense(max_length,activation='sigmoid',bias_constraint=None,kernel_initializer=init,name='attention')(state)\\nfc = Lambda(lambda x: keras.backend.expand_dims(x,axis=-1),name='RasMMA')(fc)\\nfc = Lambda(lambda x: keras.backend.repeat_elements(x,int(emb_dim/2),axis=-1))(fc)\\n# fc = keras.backend.repeat_elements(fc,256,axis=-1)\\n# fc = keras.backend.expand_dims(fc,axis=-1)\\nmul = Multiply()([fc,timesteps])\\n# mul = BatchNormalization()(mul)\\nalls = []\\ngru = (GRU(int(emb_dim/4))) #/8\\n# gru = GRU(1)\\nbn = BatchNormalization()\\ndp = Dropout(0.01)\\n\\ndense = Dense(1,activation='sigmoid')\\nfor i in range(fam_num):\\n#     alls.append(dense(bn(gru(mul))))\\n    alls.append(dense(dp(bn(gru(mul)))))\\n#     alls.append(gru(mul))\\nout = Concatenate(name='family')(alls)\\n# out = Dense(44,activation='sigmoid')(out)\\nmodel_old = Model(inputs=[sent_ids1,sentemb1], outputs=[out]) #out\\nmodel_old = multi_gpu_model(model_old , gpus=3)\\nmodel_old.load_weights('./model/LSTM_att/1stStage_44fam_0607.h5')\\nmodel_old.summary()\\n\\n# model = load_model('./model/LSTM_att/1stStage_44fam_0607.h5_all.h5')\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "sentemb1 = Input(shape=(max_length,emb_dim),name='sent_emb')\n",
    "sentemb = Masking(mask_value=0)(sentemb1)\n",
    "sent_ids1 = Input(shape=(max_length,), dtype='int32', name='sent_ids') # 輸入的api funvtion name ID\n",
    "sent_ids = Masking(mask_value=0)(sent_ids1)\n",
    "api_emb = Embedding(vocabulary_size+1, emb_dim,weights=[emb_matrix],input_length=max_length,trainable=True,name='api_emb')(sent_ids)\n",
    "\n",
    "final_emb = Add()([sentemb,api_emb])\n",
    "\n",
    "timesteps,state_h,state_c = LSTM(int(emb_dim/2),return_sequences=True,return_state=True,name='lstm1')(final_emb) #final_emb\n",
    "state = Concatenate()([state_h,state_c])\n",
    "fc = Dense(max_length,activation='sigmoid',bias_constraint=None,kernel_initializer=init,name='attention')(state)\n",
    "fc = Lambda(lambda x: keras.backend.expand_dims(x,axis=-1),name='RasMMA')(fc)\n",
    "fc = Lambda(lambda x: keras.backend.repeat_elements(x,int(emb_dim/2),axis=-1))(fc)\n",
    "# fc = keras.backend.repeat_elements(fc,256,axis=-1)\n",
    "# fc = keras.backend.expand_dims(fc,axis=-1)\n",
    "mul = Multiply()([fc,timesteps])\n",
    "# mul = BatchNormalization()(mul)\n",
    "alls = []\n",
    "gru = (GRU(int(emb_dim/4))) #/8\n",
    "# gru = GRU(1)\n",
    "bn = BatchNormalization()\n",
    "dp = Dropout(0.01)\n",
    "\n",
    "dense = Dense(1,activation='sigmoid')\n",
    "for i in range(fam_num):\n",
    "#     alls.append(dense(bn(gru(mul))))\n",
    "    alls.append(dense(dp(bn(gru(mul)))))\n",
    "#     alls.append(gru(mul))\n",
    "out = Concatenate(name='family')(alls)\n",
    "# out = Dense(44,activation='sigmoid')(out)\n",
    "model_old = Model(inputs=[sent_ids1,sentemb1], outputs=[out]) #out\n",
    "model_old = multi_gpu_model(model_old , gpus=3)\n",
    "model_old.load_weights('./model/LSTM_att/1stStage_44fam_0607.h5')\n",
    "model_old.summary()\n",
    "\n",
    "# model = load_model('./model/LSTM_att/1stStage_44fam_0607.h5_all.h5')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_old.layers[-2].save_weights('./model/LSTM_att/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_multi_label_metric(y_true, y_pred):\n",
    "    comp = K.equal(y_true, K.round(y_pred))\n",
    "    return K.cast(K.all(comp, axis=-1), K.floatx())\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
    "               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "def custom_acc1(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred,k=3)\n",
    "from keras.metrics import binary_accuracy\n",
    "def bin_acc(y_true, y_pred):\n",
    "    return binary_accuracy(y_true, y_pred)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    return tf.keras.metrics.Precision(y_true,y_pred)[1]\n",
    "def recall(y_true, y_pred):\n",
    "    return tf.keras.metrics.Recall(y_true,y_pred)[1]\n",
    "def Hamming_loss(y_true, y_pred):\n",
    "    tmp = K.abs(y_true-y_pred)\n",
    "    return K.mean(K.cast(K.greater(tmp,0.5),dtype=float))\n",
    "def hn_multilabel_loss(y_true, y_pred):\n",
    "    # Avoid divide by 0\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Multi-task loss\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))\n",
    "# from sklearn.metrics import f1_score\n",
    "# def f1_sk(y_true,y_pred):\n",
    "#     score = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "#     return score\n",
    "\n",
    "# 訓練參數\n",
    "los = [losses.binary_crossentropy,binary_focal_loss(alpha=.25, gamma=2)] # 1st stage.  f1_loss\n",
    "#SINGLE\n",
    "los = [binary_focal_loss(alpha=.25, gamma=2)] #改\n",
    "# los = [hn_multilabel_loss]\n",
    "# los = [losses.binary_crossentropy]\n",
    "# MML\n",
    "'''los = []\n",
    "for i in range(fam_num):\n",
    "    los.append(binary_focal_loss(alpha=.25, gamma=2))\n",
    "los = [losses.binary_crossentropy] + los'''\n",
    "\n",
    "\n",
    "metric = {'out_rep': bin_acc,'family': f1_metric} # 1st stage. km.f1_score()\n",
    "#SINGLE\n",
    "# metric = [f1_metric,bin_acc]\n",
    "# metric = [km.f1_score(),bin_acc,km.binary_f1_score()]\n",
    "# metric = {'RasMMA': 'acc'}\n",
    "metric = [f1_metric] #改\n",
    "#MML\n",
    "'''metrics = []\n",
    "for i in range(fam_num+1):\n",
    "    metrics.append('acc')\n",
    "# metrics = {}\n",
    "# metrics['RasMMA'] = 'acc'\n",
    "# for i in range(fam_num):\n",
    "#     metrics['fam'+str(i)]='acc'\n",
    "metric = metrics'''\n",
    "\n",
    "\n",
    "loss_weight = [1,1] #stage1 0.95,0.05  #1st stage # 2nd stage [0.01,0.99]\n",
    "#SINGLE\n",
    "loss_weight = [1]\n",
    "#MML\n",
    "'''loss_weight = []\n",
    "for i in range(fam_num):\n",
    "    loss_weight.append(0.95)\n",
    "loss_weight = [0.05] + loss_weight'''\n",
    "\n",
    "learning_rate = 5e-4#2e-4 # 2nd stage: 1e-4 @1st:2e-4 0.002\n",
    "# batch_size = 128 #32 #128\n",
    "\n",
    "num_epochs = 1000\n",
    "patien = 50\n",
    "\n",
    "model_save_path = './model/att_clf/2ndStage_44fam_0616_gru_sent2vec_copy1.h5' #改\n",
    "tensorboard_log_path = './logs/'+ model_save_path.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "optimizer = optimizers.Adam(\n",
    "            lr=learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False) #clipnorm=1. , clipvalue=1.\n",
    "# optimizer = keras.optimizers.Nadam(lr=learning_rate, clipvalue=1.) #改\n",
    "# tf.keras.optimizers.Nadam\n",
    "lr_scheduler1 = callbacks.LearningRateScheduler(\n",
    "        CosineLRSchedule(lr_high=0.0015, lr_low=1e-8, #learning_rate #改\n",
    "                         initial_period=num_epochs),\n",
    "        verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=int(patien/3),\n",
    "                                      min_lr=1e-8,mode='min')\n",
    "\n",
    "model.compile(\n",
    "            optimizer,\n",
    "            loss=los,\n",
    "            metrics=metric ,loss_weights=loss_weight)#{'word_predictions': masked_perplexity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best, early stopping, 2 models ens weight:(best=0.8,last=0.2)\n",
    "history = History()\n",
    "stop_nan = callbacks.TerminateOnNaN()\n",
    "model_callbacks = [\n",
    "        callbacks.ModelCheckpoint(\n",
    "            model_save_path, #val_f1_metric,max。val_family_f1_metric\n",
    "            monitor='val_f1_metric',mode='max' ,save_best_only=True, verbose=1,save_weights_only=True), #改\n",
    "            EarlyStopping(patience=patien,monitor='val_loss',verbose=1,mode='min'),\n",
    "        lr_scheduler, lr_scheduler1,history,stop_nan\n",
    "    ]\n",
    "model_callbacks.append(callbacks.TensorBoard(tensorboard_log_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_batch(batch_size, X_train1, X_train2 , Y_train1, Y_train2):\n",
    "    '''\n",
    "    X_train1 = sent_ids: shape為(N, max_seq_length)\n",
    "    X_train2 = sentemb: shape為(N,max_seq_length, word_embedding_size)\n",
    "    Y_train1 = class_prediction: shape為(N, max_seq_length, 1)\n",
    "    Y_train2 = family_prediction(stage2): shape為(N, fam_num)\n",
    "    '''\n",
    "    idx = np.arange(len(X_train1))\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    while True:\n",
    "        for i in idx:\n",
    "            train_X1 = X_train1[idx[i]:idx[i]+batch_size]\n",
    "            train_X2 = X_train2[idx[i]:idx[i]+batch_size]\n",
    "            train_Y1 = Y_train1[idx[i]:idx[i]+batch_size]\n",
    "            train_Y2 = Y_train2[idx[i]:idx[i]+batch_size]\n",
    "#             yield(train_X2,train_Y2)\n",
    "#             yield ([train_X1,train_X2],[train_Y1,train_Y2]) #ori\n",
    "            yield ([train_X1,train_X2],[train_Y2]) #改\n",
    "            if i == idx[-1]:\n",
    "                idx = np.arange(len(X_train1))\n",
    "                np.random.shuffle(idx)\n",
    "                break\n",
    "            \n",
    "#     data_size = X_train.shape[0]\n",
    "#     ep = data_size / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leoqaz12/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/.local/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0015.\n",
      "88/88 [==============================] - 1191s 14s/step - loss: 179.1351 - f1_metric: 0.3058 - val_loss: 79.0687 - val_f1_metric: 0.2452\n",
      "\n",
      "Epoch 00001: val_f1_metric improved from -inf to 0.24522, saving model to ./model/att_clf/2ndStage_44fam_0616_gru_sent2vec_copy1.h5\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0014999962989260677.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 44.1190 - f1_metric: 0.4195 - val_loss: 76.8503 - val_f1_metric: 0.2299\n",
      "\n",
      "Epoch 00002: val_f1_metric did not improve from 0.24522\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0014999851957407985.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 40.9729 - f1_metric: 0.4393 - val_loss: 80.4633 - val_f1_metric: 0.2339\n",
      "\n",
      "Epoch 00003: val_f1_metric did not improve from 0.24522\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0014999666905537769.\n",
      "88/88 [==============================] - 1100s 13s/step - loss: 39.8433 - f1_metric: 0.4432 - val_loss: 84.3137 - val_f1_metric: 0.1596\n",
      "\n",
      "Epoch 00004: val_f1_metric did not improve from 0.24522\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0014999407835476412.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 34.9057 - f1_metric: 0.5230 - val_loss: 74.8455 - val_f1_metric: 0.3059\n",
      "\n",
      "Epoch 00005: val_f1_metric improved from 0.24522 to 0.30595, saving model to ./model/att_clf/2ndStage_44fam_0616_gru_sent2vec_copy1.h5\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001499907474978083.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 35.1664 - f1_metric: 0.5152 - val_loss: 76.2429 - val_f1_metric: 0.3202\n",
      "\n",
      "Epoch 00006: val_f1_metric improved from 0.30595 to 0.32020, saving model to ./model/att_clf/2ndStage_44fam_0616_gru_sent2vec_copy1.h5\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001499866765173845.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 34.8742 - f1_metric: 0.5428 - val_loss: 84.6689 - val_f1_metric: 0.3144\n",
      "\n",
      "Epoch 00007: val_f1_metric did not improve from 0.32020\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001499818654536716.\n",
      "88/88 [==============================] - 1121s 13s/step - loss: 30.6444 - f1_metric: 0.5652 - val_loss: 49.6862 - val_f1_metric: 0.2204\n",
      "\n",
      "Epoch 00008: val_f1_metric did not improve from 0.32020\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0014997631435415286.\n",
      "88/88 [==============================] - 1102s 13s/step - loss: 30.7029 - f1_metric: 0.5820 - val_loss: 82.0834 - val_f1_metric: 0.1972\n",
      "\n",
      "Epoch 00009: val_f1_metric did not improve from 0.32020\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001499700232736154.\n",
      "88/88 [==============================] - 1128s 13s/step - loss: 27.7700 - f1_metric: 0.5277 - val_loss: 44.7713 - val_f1_metric: 0.2615\n",
      "\n",
      "Epoch 00010: val_f1_metric did not improve from 0.32020\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0014996299227414969.\n",
      "88/88 [==============================] - 1108s 13s/step - loss: 28.5846 - f1_metric: 0.5701 - val_loss: 87.6751 - val_f1_metric: 0.2521\n",
      "\n",
      "Epoch 00011: val_f1_metric did not improve from 0.32020\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001499552214251488.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 29.4054 - f1_metric: 0.5845 - val_loss: 95.3954 - val_f1_metric: 0.2402\n",
      "\n",
      "Epoch 00012: val_f1_metric did not improve from 0.32020\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0014994671080330788.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 30.2617 - f1_metric: 0.6063 - val_loss: 86.2843 - val_f1_metric: 0.3830\n",
      "\n",
      "Epoch 00013: val_f1_metric improved from 0.32020 to 0.38302, saving model to ./model/att_clf/2ndStage_44fam_0616_gru_sent2vec_copy1.h5\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0014993746049262334.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 29.3261 - f1_metric: 0.6047 - val_loss: 90.9376 - val_f1_metric: 0.2739\n",
      "\n",
      "Epoch 00014: val_f1_metric did not improve from 0.38302\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0014992747058439203.\n",
      "88/88 [==============================] - 1101s 13s/step - loss: 27.9976 - f1_metric: 0.6153 - val_loss: 92.5109 - val_f1_metric: 0.3548\n",
      "\n",
      "Epoch 00015: val_f1_metric did not improve from 0.38302\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0014991674117721028.\n",
      "88/88 [==============================] - 1099s 12s/step - loss: 29.6864 - f1_metric: 0.6003 - val_loss: 85.6989 - val_f1_metric: 0.3193\n",
      "\n",
      "Epoch 00016: val_f1_metric did not improve from 0.38302\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0014990527237697302.\n",
      "88/88 [==============================] - 1033s 12s/step - loss: 30.4782 - f1_metric: 0.5879 - val_loss: 86.6402 - val_f1_metric: 0.3080\n",
      "\n",
      "Epoch 00017: val_f1_metric did not improve from 0.38302\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0014989306429687268.\n",
      "88/88 [==============================] - 1034s 12s/step - loss: 28.3877 - f1_metric: 0.6193 - val_loss: 89.1899 - val_f1_metric: 0.3142\n",
      "\n",
      "Epoch 00018: val_f1_metric did not improve from 0.38302\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0014988011705739808.\n",
      "88/88 [==============================] - 1032s 12s/step - loss: 26.7993 - f1_metric: 0.6105 - val_loss: 79.4480 - val_f1_metric: 0.3846\n",
      "\n",
      "Epoch 00019: val_f1_metric improved from 0.38302 to 0.38460, saving model to ./model/att_clf/2ndStage_44fam_0616_gru_sent2vec_copy1.h5\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0014986643078633325.\n",
      "88/88 [==============================] - 1031s 12s/step - loss: 27.1136 - f1_metric: 0.6468 - val_loss: 89.7284 - val_f1_metric: 0.2830\n",
      "\n",
      "Epoch 00020: val_f1_metric did not improve from 0.38460\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0014985200561875615.\n",
      "88/88 [==============================] - 1032s 12s/step - loss: 27.6477 - f1_metric: 0.6496 - val_loss: 91.4150 - val_f1_metric: 0.1997\n",
      "\n",
      "Epoch 00021: val_f1_metric did not improve from 0.38460\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001498368416970374.\n",
      "88/88 [==============================] - 1034s 12s/step - loss: 27.8374 - f1_metric: 0.6235 - val_loss: 89.8325 - val_f1_metric: 0.3527\n",
      "\n",
      "Epoch 00022: val_f1_metric did not improve from 0.38460\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001498209391708387.\n",
      "88/88 [==============================] - 1036s 12s/step - loss: 25.1408 - f1_metric: 0.6341 - val_loss: 92.4108 - val_f1_metric: 0.3524\n",
      "\n",
      "Epoch 00023: val_f1_metric did not improve from 0.38460\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0014980429819711166.\n",
      "88/88 [==============================] - 1036s 12s/step - loss: 25.0658 - f1_metric: 0.6544 - val_loss: 107.2433 - val_f1_metric: 0.2810\n",
      "\n",
      "Epoch 00024: val_f1_metric did not improve from 0.38460\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001497869189400959.\n",
      "88/88 [==============================] - 1036s 12s/step - loss: 27.3239 - f1_metric: 0.6349 - val_loss: 94.0012 - val_f1_metric: 0.3133\n",
      "\n",
      "Epoch 00025: val_f1_metric did not improve from 0.38460\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0014976880157131773.\n",
      "88/88 [==============================] - 1034s 12s/step - loss: 25.8693 - f1_metric: 0.6015 - val_loss: 94.3807 - val_f1_metric: 0.3435\n",
      "\n",
      "Epoch 00026: val_f1_metric did not improve from 0.38460\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0014974994626958823.\n",
      "88/88 [==============================] - 1060s 12s/step - loss: 25.6689 - f1_metric: 0.6611 - val_loss: 95.0855 - val_f1_metric: 0.3663\n",
      "\n",
      "Epoch 00027: val_f1_metric did not improve from 0.38460\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001497303532210016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1107s 13s/step - loss: 25.8911 - f1_metric: 0.6492 - val_loss: 93.7547 - val_f1_metric: 0.2693\n",
      "\n",
      "Epoch 00028: val_f1_metric did not improve from 0.38460\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0014971002261893337.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 25.2370 - f1_metric: 0.6594 - val_loss: 92.2951 - val_f1_metric: 0.3798\n",
      "\n",
      "Epoch 00029: val_f1_metric did not improve from 0.38460\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0014968895466403833.\n",
      "88/88 [==============================] - 1105s 13s/step - loss: 24.4290 - f1_metric: 0.6689 - val_loss: 88.6834 - val_f1_metric: 0.3847\n",
      "\n",
      "Epoch 00030: val_f1_metric improved from 0.38460 to 0.38468, saving model to ./model/att_clf/2ndStage_44fam_0616_gru_sent2vec_copy1.h5\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001496671495642487.\n",
      "88/88 [==============================] - 1105s 13s/step - loss: 24.9927 - f1_metric: 0.6663 - val_loss: 95.4823 - val_f1_metric: 0.3356\n",
      "\n",
      "Epoch 00031: val_f1_metric did not improve from 0.38468\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0014964460753477203.\n",
      "88/88 [==============================] - 1105s 13s/step - loss: 27.0047 - f1_metric: 0.6380 - val_loss: 103.3385 - val_f1_metric: 0.3244\n",
      "\n",
      "Epoch 00032: val_f1_metric did not improve from 0.38468\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0014962132879808904.\n",
      "88/88 [==============================] - 1135s 13s/step - loss: 25.6044 - f1_metric: 0.6458 - val_loss: 55.1143 - val_f1_metric: 0.2959\n",
      "\n",
      "Epoch 00033: val_f1_metric did not improve from 0.38468\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0014959731358395142.\n",
      "88/88 [==============================] - 1109s 13s/step - loss: 25.0909 - f1_metric: 0.6511 - val_loss: 97.4104 - val_f1_metric: 0.2397\n",
      "\n",
      "Epoch 00034: val_f1_metric did not improve from 0.38468\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0014957256212937973.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 24.6680 - f1_metric: 0.6632 - val_loss: 87.2436 - val_f1_metric: 0.3053\n",
      "\n",
      "Epoch 00035: val_f1_metric did not improve from 0.38468\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0014954707467866076.\n",
      "88/88 [==============================] - 1109s 13s/step - loss: 23.0940 - f1_metric: 0.6723 - val_loss: 93.2129 - val_f1_metric: 0.3748\n",
      "\n",
      "Epoch 00036: val_f1_metric did not improve from 0.38468\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0014952085148334537.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 27.8560 - f1_metric: 0.6244 - val_loss: 92.5003 - val_f1_metric: 0.3145\n",
      "\n",
      "Epoch 00037: val_f1_metric did not improve from 0.38468\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0014949389280224594.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 24.8327 - f1_metric: 0.6721 - val_loss: 95.6877 - val_f1_metric: 0.2693\n",
      "\n",
      "Epoch 00038: val_f1_metric did not improve from 0.38468\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0014946619890143374.\n",
      "88/88 [==============================] - 1107s 13s/step - loss: 26.4822 - f1_metric: 0.6476 - val_loss: 91.3103 - val_f1_metric: 0.3482\n",
      "\n",
      "Epoch 00039: val_f1_metric did not improve from 0.38468\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0014943777005423642.\n",
      "88/88 [==============================] - 1107s 13s/step - loss: 25.0043 - f1_metric: 0.6543 - val_loss: 93.1412 - val_f1_metric: 0.2973\n",
      "\n",
      "Epoch 00040: val_f1_metric did not improve from 0.38468\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001494086065412352.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 25.3069 - f1_metric: 0.6632 - val_loss: 98.8957 - val_f1_metric: 0.3600\n",
      "\n",
      "Epoch 00041: val_f1_metric did not improve from 0.38468\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.0014937870865026218.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 26.2784 - f1_metric: 0.6495 - val_loss: 86.4229 - val_f1_metric: 0.3902\n",
      "\n",
      "Epoch 00042: val_f1_metric improved from 0.38468 to 0.39022, saving model to ./model/att_clf/2ndStage_44fam_0616_gru_sent2vec_copy1.h5\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.0014934807667639747.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 25.7163 - f1_metric: 0.6626 - val_loss: 88.2048 - val_f1_metric: 0.3494\n",
      "\n",
      "Epoch 00043: val_f1_metric did not improve from 0.39022\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001493167109219663.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 24.1937 - f1_metric: 0.6835 - val_loss: 90.8378 - val_f1_metric: 0.3581\n",
      "\n",
      "Epoch 00044: val_f1_metric did not improve from 0.39022\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0014928461169653599.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 25.4915 - f1_metric: 0.6507 - val_loss: 97.7579 - val_f1_metric: 0.3517\n",
      "\n",
      "Epoch 00045: val_f1_metric did not improve from 0.39022\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.0014925177931691296.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 25.2580 - f1_metric: 0.6402 - val_loss: 104.6371 - val_f1_metric: 0.3210\n",
      "\n",
      "Epoch 00046: val_f1_metric did not improve from 0.39022\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.0014921821410713951.\n",
      "88/88 [==============================] - 1109s 13s/step - loss: 24.2658 - f1_metric: 0.6604 - val_loss: 99.2184 - val_f1_metric: 0.3166\n",
      "\n",
      "Epoch 00047: val_f1_metric did not improve from 0.39022\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.0014918391639849075.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 23.7936 - f1_metric: 0.6683 - val_loss: 94.9635 - val_f1_metric: 0.3531\n",
      "\n",
      "Epoch 00048: val_f1_metric did not improve from 0.39022\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.0014914888652947118.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 25.2808 - f1_metric: 0.6555 - val_loss: 100.9681 - val_f1_metric: 0.3435\n",
      "\n",
      "Epoch 00049: val_f1_metric did not improve from 0.39022\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001491131248458115.\n",
      "88/88 [==============================] - 1107s 13s/step - loss: 25.6326 - f1_metric: 0.6555 - val_loss: 105.7084 - val_f1_metric: 0.3128\n",
      "\n",
      "Epoch 00050: val_f1_metric did not improve from 0.39022\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0014907663170046503.\n",
      "88/88 [==============================] - 1105s 13s/step - loss: 25.2367 - f1_metric: 0.6549 - val_loss: 90.4200 - val_f1_metric: 0.3569\n",
      "\n",
      "Epoch 00051: val_f1_metric did not improve from 0.39022\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0014903940745360444.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 27.0247 - f1_metric: 0.6186 - val_loss: 90.8530 - val_f1_metric: 0.3762\n",
      "\n",
      "Epoch 00052: val_f1_metric did not improve from 0.39022\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0014900145247261798.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 24.7025 - f1_metric: 0.6673 - val_loss: 88.8027 - val_f1_metric: 0.3173\n",
      "\n",
      "Epoch 00053: val_f1_metric did not improve from 0.39022\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0014896276713210607.\n",
      "88/88 [==============================] - 1105s 13s/step - loss: 25.5257 - f1_metric: 0.6536 - val_loss: 81.8985 - val_f1_metric: 0.3734\n",
      "\n",
      "Epoch 00054: val_f1_metric did not improve from 0.39022\n",
      "Epoch 55/1000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0014892335181387727.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 25.5454 - f1_metric: 0.6444 - val_loss: 85.7310 - val_f1_metric: 0.3268\n",
      "\n",
      "Epoch 00055: val_f1_metric did not improve from 0.39022\n",
      "Epoch 56/1000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0014888320690694496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1106s 13s/step - loss: 23.0907 - f1_metric: 0.6828 - val_loss: 103.8245 - val_f1_metric: 0.3082\n",
      "\n",
      "Epoch 00056: val_f1_metric did not improve from 0.39022\n",
      "Epoch 57/1000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0014884233280752315.\n",
      "88/88 [==============================] - 1105s 13s/step - loss: 24.0134 - f1_metric: 0.6709 - val_loss: 91.9742 - val_f1_metric: 0.3095\n",
      "\n",
      "Epoch 00057: val_f1_metric did not improve from 0.39022\n",
      "Epoch 58/1000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0014880072991902266.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 23.5708 - f1_metric: 0.6769 - val_loss: 90.7901 - val_f1_metric: 0.3550\n",
      "\n",
      "Epoch 00058: val_f1_metric did not improve from 0.39022\n",
      "Epoch 59/1000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0014875839865204723.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 21.7525 - f1_metric: 0.7233 - val_loss: 90.7290 - val_f1_metric: 0.3400\n",
      "\n",
      "Epoch 00059: val_f1_metric did not improve from 0.39022\n",
      "Epoch 60/1000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0014871533942438936.\n",
      "88/88 [==============================] - 1106s 13s/step - loss: 23.1603 - f1_metric: 0.6306 - val_loss: 82.9710 - val_f1_metric: 0.2928\n",
      "\n",
      "Epoch 00060: val_f1_metric did not improve from 0.39022\n",
      "Epoch 00060: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "H = model.fit_generator(\n",
    "    generator=training_batch(batch_size=batch_size,X_train1=train_emb_api,X_train2=train_emb ,\n",
    "                                             Y_train1=train_rep_ans,Y_train2=train_fam_ans) #Y_train2\n",
    "#                     generator=training_batch(batch_size=batch_size,X_train1=valid_emb_api,X_train2=valid_emb ,\n",
    "#                                              Y_train1=train_rep_ans,Y_train2=train_fam_ans)\n",
    "                        , steps_per_epoch=int(np.ceil(len(train_emb_api)/batch_size)) ,\n",
    "                    epochs=num_epochs,callbacks=model_callbacks\n",
    "#                    ,validation_data= ([valid_emb_api,valid_emb], [valid_rep_ans,valid_fam_ans]) #ori\n",
    "#                    ,validation_data= (valid_emb, valid_fam_ans) \n",
    "                   ,validation_data= ([valid_emb_api,valid_emb], [valid_fam_ans]) #ori #改\n",
    "#                    ,validation_data= ([valid_emb_api,valid_emb], [valid_rep_ans]+valid_Y2) #validY2\n",
    "                    ,max_queue_size=10  #,class_weight=[None,fam_weights] #改\n",
    "                    ,workers=10,use_multiprocessing=True   \n",
    "                   ,shuffle=True,verbose=1)\n",
    "model.save(model_save_path+\"_all.h5\")\n",
    "#1st:train 0_1_prediction=0.14XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "* multi model weights 儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-32b396342986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model_.load_weights(model_save_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "# model_ = model.layers[-2]\n",
    "# model_.load_weights(model_save_path)\n",
    "# model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights(model_save_path)\n",
    "# model_ = model.layers[-3]\n",
    "# model_.save_weights(model_save_path)\n",
    "# model_.summary()\n",
    "pickle.dump(file=open(tensorboard_log_path + '/'+'2nd2Stage_H.pkl','wb'),obj=H) #改\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json, model_from_yaml\n",
    "json_string = model.to_json()\n",
    "yaml_string = model.to_yaml()\n",
    "pickle.dump(file=open(tensorboard_log_path + '/'+'2nd2Stage_arch.pkl','wb'),obj=(json_string,yaml_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_weights('./model/LSTM_att/1stStage_44fam_0610.h5')\n",
    "# model.load_weights('./model/att_clf/1stStage_44fam_0611_copy1.h5')\n",
    "# score = model.evaluate([valid_emb_api,valid_emb], [valid_rep_ans]+valid_Y2)\n",
    "print(len(test_emb_api)) #改\n",
    "ans = model.predict([test_emb_api,test_emb]) #改\n",
    "y_true = test_fam_ans #改\n",
    "# ans = model.predict([valid_emb_api,valid_emb])\n",
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rep_ans[113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33110094, 0.26109296, 0.17362013, 0.15649804, 0.14994743,\n",
       "       0.25586426, 0.07207608, 0.0422487 , 0.15643859, 0.13885641,\n",
       "       0.09513095, 0.1076369 , 0.11274558, 0.1414693 , 0.06398544,\n",
       "       0.11231145, 0.0610975 , 0.03645003, 0.03144044, 0.00495178,\n",
       "       0.02880701, 0.05781603, 0.17894429, 0.00076652, 0.04401305,\n",
       "       0.1177654 , 0.00458246, 0.02128163, 0.00547022, 0.0167802 ,\n",
       "       0.05839851, 0.02254871, 0.00292459, 0.04838032, 0.02456126,\n",
       "       0.07602081, 0.00565934, 0.01053882, 0.01560137, 0.28512704,\n",
       "       0.00831279, 0.00371325, 0.00058794, 0.00589615], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[1][113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6530128 ],\n",
       "       [0.6269398 ],\n",
       "       [0.504724  ],\n",
       "       [0.5047246 ],\n",
       "       [0.504725  ],\n",
       "       [0.5047249 ],\n",
       "       [0.38633832],\n",
       "       [0.5844016 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.9855372 ],\n",
       "       [0.5844019 ],\n",
       "       [0.5844015 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.5844019 ],\n",
       "       [0.9855267 ],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.58440256],\n",
       "       [0.5844016 ],\n",
       "       [0.9855195 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ],\n",
       "       [0.5727547 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[0][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_.save_weights('./model/LSTM_att/test4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_ = model.layers[-2]\n",
    "layer_name = 'lambda_1' #lambda_1 multiply_1  #9~12\n",
    "intermediate_layer_model = Model(inputs=model_.inputs,\n",
    "                                 outputs=model_.layers[9].output)\n",
    "intermediate_output = intermediate_layer_model.predict([valid_emb_api,valid_emb])\n",
    "intermediate_output[113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(intermediate_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output[113].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intermediate_output[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_.summary() #multiply_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 44) 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "# y_true = np.squeeze(test_fam_ans)\n",
    "# y_true = np.squeeze(valid_fam_ans1)\n",
    "# y_pred = np.squeeze(predict_fam)\n",
    "final_ans = []\n",
    "for sample in ans[1]:\n",
    "    sample_ans = []\n",
    "    for value in sample:\n",
    "        if value < 0.28: #0.26 #0.33\n",
    "            sample_ans.append(0)\n",
    "        else:\n",
    "            sample_ans.append(1)\n",
    "    final_ans.append(sample_ans)\n",
    "final_ans = np.array(final_ans)\n",
    "print(final_ans.shape , sum(final_ans[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 44) (424, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4883720930232558, 0.3583617747440273, 0.4133858267716536)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_true = test_fam_ans\n",
    "print(y_true.shape , final_ans.shape)\n",
    "recall = recall_score(y_true=y_true, y_pred=final_ans, average='micro')\n",
    "precision = precision_score(y_true=y_true, y_pred=final_ans, average='micro')\n",
    "f1 = f1_score(y_true=y_true, y_pred=final_ans, average='micro')\n",
    "recall ,precision, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
