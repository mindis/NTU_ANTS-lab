{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil,pickle,tqdm,sys,random,re,string,pause, datetime,glob\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# # The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" \n",
    "import keras\n",
    "import sent2vec\n",
    "import seq2seq\n",
    "from seq2seq.models import AttentionSeq2Seq\n",
    "from seq2seq.models import Seq2Seq\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from math import log, floor\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils import *\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras import *\n",
    "from keras.engine.topology import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import *\n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import *\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.cluster import *\n",
    "from sklearn.metrics.pairwise import *\n",
    "\n",
    "# from collections import Counter\n",
    "from keras.utils.generic_utils import *\n",
    "from keras import regularizers\n",
    "import unicodedata as udata\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "from keras import backend \n",
    "from imblearn.ensemble import *\n",
    "from imblearn.combine import *\n",
    "# from python.keras import backend \n",
    "# Embedding(10,20)\n",
    "from keras_transformer.extras import ReusableEmbedding, TiedOutputEmbedding\n",
    "from keras_transformer.position import TransformerCoordinateEmbedding\n",
    "from keras_transformer.transformer import TransformerACT, TransformerBlock\n",
    "from keras_transformer.bert import (\n",
    "    BatchGeneratorForBERT, masked_perplexity,\n",
    "    MaskedPenalizedSparseCategoricalCrossentropy)\n",
    "\n",
    "import keras_metrics as km\n",
    "from keras_trans_mask import RemoveMask, RestoreMask\n",
    "\n",
    "from keras_multi_head import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 213, 192)          0         \n",
      "_________________________________________________________________\n",
      "Multi-Head (MultiHeadAttenti (None, 213, 192)          148224    \n",
      "_________________________________________________________________\n",
      "multi_head_13 (MultiHead)    (None, 213, 12, 2)        4632      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5112)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 44)                224972    \n",
      "=================================================================\n",
      "Total params: 377,828\n",
      "Trainable params: 377,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras_multi_head import MultiHeadAttention\n",
    "\n",
    "input_layer = keras.layers.Input(\n",
    "    shape=(213, int(768/2)),\n",
    "    name='Input',\n",
    ")\n",
    "att_layer = MultiHeadAttention(\n",
    "    head_num=48,\n",
    "    name='Multi-Head',\n",
    ")(input_layer)\n",
    "att_layer = MultiHead(Dense(int(768/64)),layer_num=2)(att_layer)\n",
    "att_layer = Flatten()(att_layer)\n",
    "att_layer = Dense(44)(att_layer)\n",
    "model = keras.models.Model(inputs=input_layer, outputs=att_layer)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics={},\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import transformer_bert_model\n",
    "from bpe import BPEEncoder\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of sent2vec vector: (424, 213, 768) (424, 213) (424, 44) (424, 213, 1)\n"
     ]
    }
   ],
   "source": [
    "train_emb, train_emb_api, train_fam_ans, train_rep_ans = pickle.load(open('data/tree-rep-profiles-partial/TRAIN_vec.pkl','rb'))\n",
    "valid_emb, valid_emb_api,valid_fam_ans,valid_rep_ans = pickle.load(open('data/tree-rep-profiles-partial/DEV_vec.pkl','rb'))\n",
    "test_emb, test_emb_api,test_fam_ans,test_rep_ans = pickle.load(open('data/tree-rep-profiles-partial/TEST_vec.pkl','rb'))\n",
    "# print('train of sent2vec vector:',train_emb.shape,train_emb_api.shape,train_fam_ans.shape,train_rep_ans.shape)\n",
    "# print('valid of sent2vec vector:',valid_emb.shape,valid_emb_api.shape,valid_fam_ans.shape,valid_rep_ans.shape)\n",
    "train_rep_ans = np.expand_dims(train_rep_ans,axis=-1)\n",
    "valid_rep_ans = np.expand_dims(valid_rep_ans,axis=-1)\n",
    "test_rep_ans = np.expand_dims(test_rep_ans,axis=-1)\n",
    "print('test of sent2vec vector:',test_emb.shape,test_emb_api.shape,test_fam_ans.shape,test_rep_ans.shape)\n",
    "emb_matrix = pickle.load(open('data/tree-rep-profiles-partial/api_emb_matrix.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train only fam hash unique\n",
    "def unique_hash(train_emb,train_emb_api,train_fam_ans,train_rep_ans):\n",
    "    unique , indx = np.unique(train_emb, axis=0, return_index=True)\n",
    "    emb_api = train_emb_api[indx]\n",
    "    fam = train_fam_ans[indx]\n",
    "    rep = train_rep_ans[indx]\n",
    "    print(unique.shape,emb_api.shape,fam.shape)\n",
    "    return unique,emb_api,fam,rep #改\n",
    "# train_emb,train_emb_api,train_fam_ans,train_rep_ans = unique_hash(train_emb,train_emb_api,train_fam_ans,train_rep_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle(X, X2 ,X3,X4):\n",
    "#     X3 = np.take(train_fam_ans,[0],axis=-1) #只train第幾個familiy\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "#     print(X.shape, Y.shape)\n",
    "    return (X[randomize], X2[randomize],X3[randomize],X4[randomize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train of sent2vec vector: (11141, 213, 768) (11141, 213) (11141, 44) (11141, 213, 1)\n",
      "valid of sent2vec vector: (437, 213, 768) (437, 213) (437, 44) (437, 213, 1)\n"
     ]
    }
   ],
   "source": [
    "train_emb, train_emb_api, train_fam_ans, train_rep_ans = _shuffle(train_emb, train_emb_api, train_fam_ans, train_rep_ans)\n",
    "valid_emb, valid_emb_api,valid_fam_ans,valid_rep_ans = _shuffle(valid_emb, valid_emb_api,valid_fam_ans,valid_rep_ans)\n",
    "\n",
    "# test_emb, test_emb_api,test_fam_ans,test_rep_ans  = _shuffle(test_emb,test_emb_api,test_fam_ans,test_rep_ans)\n",
    "\n",
    "print('train of sent2vec vector:',train_emb.shape,train_emb_api.shape,train_fam_ans.shape,train_rep_ans.shape)\n",
    "print('valid of sent2vec vector:',valid_emb.shape,valid_emb_api.shape,valid_fam_ans.shape,valid_rep_ans.shape)\n",
    "\n",
    "# print('test of sent2vec vector:',test_emb.shape,test_emb_api.shape,test_fam_ans.shape,test_rep_ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = 'no'\n",
    "\n",
    "# dim-wise scaling\n",
    "def scaling(trainX,validX,testX,scale='min_max'):\n",
    "#     if scale == 'min_max':\n",
    "    max_value = max([np.max(trainX) , np.max(validX),np.max(testX)])\n",
    "    min_value = min([np.min(trainX),np.min(validX),np.min(testX)])\n",
    "\n",
    "    trainX = (trainX - min_value) / (max_value - min_value)\n",
    "    validX = (validX - min_value) / (max_value - min_value )\n",
    "    testX = (testX - min_value) / (max_value - min_value )\n",
    "    print(np.max(trainX),np.max(validX))\n",
    "    return trainX,validX,testX , max_value , min_value\n",
    "def scaling(trainX,validX,testX,scale='mean_dim',):\n",
    "#     if scale == 'min_max':\n",
    "    alls = np.concatenate((trainX,validX,testX),axis=0)\n",
    "    mean = np.mean(alls,axis=-1)\n",
    "    mean = np.mean(mean,axis=0)\n",
    "    mean = np.expand_dims(mean,axis=-1)\n",
    "    mean = np.repeat(mean,trainX.shape[2],axis=-1)\n",
    "    mean = np.expand_dims(mean,axis=0)\n",
    "    mean_train = np.repeat(mean,trainX.shape[0],axis=0)\n",
    "    mean_valid = np.repeat(mean,validX.shape[0],axis=0)\n",
    "    mean_test = np.repeat(mean,testX.shape[0],axis=0)\n",
    "    std = np.std(alls,axis=-1)\n",
    "    std = np.std(std,axis=0)\n",
    "    std = np.expand_dims(std,axis=-1)\n",
    "    std = np.repeat(std,validX.shape[2],axis=-1)\n",
    "    std_train = np.repeat(std,trainX.shape[0],axis=0)\n",
    "    std_valid = np.repeat(std,validX.shape[0],axis=0)\n",
    "    std_test = np.repeat(std,testX.shape[0],axis=0)\n",
    "#     min_value = min([np.min(trainX),np.min(validX),np.min(testX)])\n",
    "\n",
    "    trainX = (trainX - mean) / (std + 1e-10)\n",
    "    validX = (validX - mean) / (std + 1e-10)\n",
    "    testX = (testX - mean) / (std + 1e-10)\n",
    "#     print(np.max(trainX),np.max(validX))\n",
    "    return trainX,validX,testX , mean , std\n",
    "\n",
    "# train_emb,valid_emb,test_emb , max_value,min_value = scaling(train_emb,valid_emb,test_emb)   \n",
    "# print(valid_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2998, 4344, 1326,  867,  294,  234,  300,  141,  264,  272,  100,\n",
       "        202,  202,   58,   76,  586,   74,   70,   97,   65,   76,  103,\n",
       "        441,   69,   90,  114,   90,   44,   67,   58,  229,   42,   78,\n",
       "         91,  151,  157,   41,   99,   20,   24,   38,   47,   30,  112])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_fam_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kk = np.mean(train_emb,axis=-1)\n",
    "# kk = np.mean(kk,axis=0)\n",
    "# kk = np.expand_dims(kk,axis=0)\n",
    "# kk = np.repeat(kk,100,axis=0)\n",
    "# kk = np.expand_dims(kk,axis=-1)\n",
    "# kk = np.repeat(kk,768,axis=-1)\n",
    "# kk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kkk = (emb_matrix - kk)/kk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kk = np.std(emb_matrix,axis=-1)\n",
    "# kk = np.expand_dims(kk,axis=-1)\n",
    "# kk = np.repeat(kk,768,axis=-1)\n",
    "# kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bc = SMOTEENN()\n",
    "# N,t,d = train_emb.shape\n",
    "# train_emb_ = train_emb.reshape(N,t*d)\n",
    "# train_fam_ans_ = train_fam_ans.reshape(N,)\n",
    "# train_emb_ , train_fam_ans_  = bc.fit_resample(train_emb_, train_fam_ans_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_emb = train_emb_.reshape(-1,t,d)\n",
    "# train_fam_ans = train_fam_ans_.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.3664174982464374,\n",
       " 1: 1.0,\n",
       " 2: 2.1821960061631724,\n",
       " 3: 2.6070792001284384,\n",
       " 4: 3.688538409570299,\n",
       " 5: 3.916797061551279,\n",
       " 6: 3.6683357022527794,\n",
       " 7: 4.423358286530812,\n",
       " 8: 3.7961690737626643,\n",
       " 9: 3.766316110612983,\n",
       " 10: 4.766947990920889,\n",
       " 11: 4.063850479507775,\n",
       " 12: 4.063850479507775,\n",
       " 13: 5.311675166362561,\n",
       " 14: 5.041384836622649,\n",
       " 15: 2.9987983873319677,\n",
       " 16: 5.068053083704811,\n",
       " 17: 5.123622934859622,\n",
       " 18: 4.7974071984055975,\n",
       " 19: 5.1977309070133435,\n",
       " 20: 5.041384836622649,\n",
       " 21: 4.737389188679344,\n",
       " 22: 3.2830733014621343,\n",
       " 23: 5.138011672311721,\n",
       " 24: 4.872308506578715,\n",
       " 25: 4.635919728514485,\n",
       " 26: 4.872308506578715,\n",
       " 27: 5.587928542990719,\n",
       " 28: 5.167425557518015,\n",
       " 29: 5.311675166362561,\n",
       " 30: 3.938396173354741,\n",
       " 31: 5.634448558625612,\n",
       " 32: 5.015409350219389,\n",
       " 33: 4.8612586703921306,\n",
       " 34: 4.354838340094056,\n",
       " 35: 4.315872371560673,\n",
       " 36: 5.658546110204672,\n",
       " 37: 4.7769983267743905,\n",
       " 38: 6.376385903354989,\n",
       " 39: 6.194064346561035,\n",
       " 40: 5.734532017182595,\n",
       " 41: 5.521970575198922,\n",
       " 42: 5.970920795246825,\n",
       " 43: 4.653619305613886}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = sum(train_fam_ans) / sum(sum(train_fam_ans))\n",
    "fam_weights={}\n",
    "for i in range(len(class_weights)):\n",
    "    fam_weights[i] = 1/class_weights[i]\n",
    "fam_weights\n",
    "\n",
    "all_fam = sum(train_fam_ans)\n",
    "for i in range(len(all_fam)):\n",
    "    fam_weights[i] = all_fam[i]\n",
    "fam_weights\n",
    "\n",
    "import math\n",
    "def create_class_weight(labels_dict,mu=0.79): #0.79 #0.46 #改\n",
    "    total = np.sum(np.array(list(labels_dict.values())))\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "\n",
    "    for key in keys:\n",
    "        score = math.log(mu*total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "fam_weights = create_class_weight(fam_weights)\n",
    "fam_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# temp = list(fam_weights.values())\n",
    "# max_value = np.max(temp)\n",
    "# for i in range(len(fam_weights)):\n",
    "#     fam_weights[i] = fam_weights[i]/max_value\n",
    "# fam_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 768 #被除數\n",
    "num_heads = 2#除數，要整除\n",
    "max_length = 213 # max sequence length\n",
    "fam_num = train_fam_ans.shape[1]\n",
    "vocabulary_size = 26\n",
    "transformer_depth = 1\n",
    "transformer_dropout = 0.1\n",
    "l2_reg_penalty = 1e-5#1e-4\n",
    "dp_rate = 0.1\n",
    "\n",
    "traina = True #改\n",
    "batch_size = 64 #改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrain = keras.constraints.MinMaxNorm(min_value=0.0, max_value=0.0, rate=1.0, axis=0)\n",
    "init = keras.initializers.Ones()\n",
    "coordinate_embedding_layer = TransformerCoordinateEmbedding(\n",
    "        transformer_depth , name='coordinate_embedding')\n",
    "act_layer = TransformerACT(\n",
    "            name='adaptive_computation_time')\n",
    "\n",
    "transformer_block = TransformerBlock(\n",
    "            name='transformer', num_heads=num_heads,\n",
    "            residual_dropout=transformer_dropout,\n",
    "            attention_dropout=transformer_dropout,\n",
    "            # Allow bi-directional attention\n",
    "            use_masking=False)\n",
    "add_segment_layer = Add(name='add_segment')\n",
    "l2_regularizer = (regularizers.l2(l2_reg_penalty) if l2_reg_penalty else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leoqaz12/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "sentemb1 = Input(shape=(max_length,emb_dim),name='sent_emb')\n",
    "sentemb = Masking(mask_value=0)(sentemb1)\n",
    "#shape=(max_length,emb_dim),,batch_shape=(batch_size,max_length,emb_dim)\n",
    "sent_ids1 = Input(shape=(max_length,), dtype='int32', name='sent_ids') # 輸入的api funvtion name ID\n",
    "sent_ids = Masking(mask_value=0)(sent_ids1)\n",
    "#shape=(max_length,),batch_shape=(batch_size,max_length)\n",
    "api_emb = Embedding(vocabulary_size+1, emb_dim,weights=[emb_matrix],input_length=max_length\n",
    "                    ,trainable=True,name='api_emb')(sent_ids) #改\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment_embeddings = Add()([sentemb,api_emb])\n",
    "# next_step_input1 = RemoveMask()(segment_embeddings)\n",
    "# next_step_input = coordinate_embedding_layer(next_step_input1, step=0,trainable=traina) #next_step_input_emb\n",
    "# next_step_input= RestoreMask()([next_step_input,segment_embeddings])\n",
    "# next_step_input = add_segment_layer([next_step_input, api_emb]) \n",
    "\n",
    "att_layer = MultiHeadAttention(\n",
    "    head_num=num_heads, trainable=True,\n",
    "    name='Multi-Head')(segment_embeddings) #改\n",
    "next_step_input = BatchNormalization()(att_layer)\n",
    "att_in = Dense(32,kernel_initializer=keras.initializers.lecun_normal(),activation='selu', # 改\n",
    "               name='attention_in',trainable=True,kernel_regularizer=l2_regularizer)(next_step_input)\n",
    "rep_prediction = (\n",
    "        Dense(1, name='0_1_predict_32', activation='sigmoid') # hard_sigmoid\n",
    "    (att_in))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leoqaz12/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "mul = multiply([segment_embeddings,rep_prediction],name='mul')\n",
    "mul = BatchNormalization()(mul)\n",
    "bn = BatchNormalization()\n",
    "dp = Dropout(dp_rate)\n",
    "dense1 = Dense(int(emb_dim/8),kernel_initializer=keras.initializers.lecun_normal(),activation='selu',\n",
    "              kernel_regularizer=l2_regularizer,name='dense1')\n",
    "dense2 = Dense(32,kernel_initializer=keras.initializers.lecun_normal(),activation='selu',\n",
    "              name='dense2')\n",
    "dense3 = Dense(1,kernel_initializer=keras.initializers.lecun_normal(),activation='sigmoid',\n",
    "              name='dense3')\n",
    "gru = GRU(int(emb_dim/4), dropout=dp_rate, recurrent_dropout=dp_rate,name='gru_64')\n",
    "alls = []\n",
    "for i in range(fam_num):\n",
    "    alls.append(dense2(bn(gru(mul))))\n",
    "#     alls.append(dense3(dense2(dp(bn(dense1(BatchNormalization()(gru(mul))))))))\n",
    "out = Concatenate()(alls)\n",
    "out = BatchNormalization()(out)\n",
    "bn = BatchNormalization()\n",
    "all_out = []\n",
    "for i in range(fam_num):\n",
    "    all_out.append(dense3(bn(dense1(out))))\n",
    "out1 = Concatenate()(all_out)\n",
    "# out = Dense(44,activation='sigmoid',name='family_out')(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sent_ids (InputLayer)           (None, 213)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sent_emb (InputLayer)           (None, 213, 768)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, 213)          0           sent_ids[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 213, 768)     0           sent_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "api_emb (Embedding)             (None, 213, 768)     20736       masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 213, 768)     0           masking_1[0][0]                  \n",
      "                                                                 api_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Multi-Head (MultiHeadAttention) (None, 213, 768)     2362368     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 213, 768)     3072        Multi-Head[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_in (Dense)            (None, 213, 32)      24608       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "0_1_predict_32 (Dense)          (None, 213, 1)       33          attention_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mul (Multiply)                  (None, 213, 768)     0           add_1[0][0]                      \n",
      "                                                                 0_1_predict_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 213, 768)     3072        mul[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gru_64 (GRU)                    (None, 192)          553536      batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 192)          768         gru_64[0][0]                     \n",
      "                                                                 gru_64[1][0]                     \n",
      "                                                                 gru_64[2][0]                     \n",
      "                                                                 gru_64[3][0]                     \n",
      "                                                                 gru_64[4][0]                     \n",
      "                                                                 gru_64[5][0]                     \n",
      "                                                                 gru_64[6][0]                     \n",
      "                                                                 gru_64[7][0]                     \n",
      "                                                                 gru_64[8][0]                     \n",
      "                                                                 gru_64[9][0]                     \n",
      "                                                                 gru_64[10][0]                    \n",
      "                                                                 gru_64[11][0]                    \n",
      "                                                                 gru_64[12][0]                    \n",
      "                                                                 gru_64[13][0]                    \n",
      "                                                                 gru_64[14][0]                    \n",
      "                                                                 gru_64[15][0]                    \n",
      "                                                                 gru_64[16][0]                    \n",
      "                                                                 gru_64[17][0]                    \n",
      "                                                                 gru_64[18][0]                    \n",
      "                                                                 gru_64[19][0]                    \n",
      "                                                                 gru_64[20][0]                    \n",
      "                                                                 gru_64[21][0]                    \n",
      "                                                                 gru_64[22][0]                    \n",
      "                                                                 gru_64[23][0]                    \n",
      "                                                                 gru_64[24][0]                    \n",
      "                                                                 gru_64[25][0]                    \n",
      "                                                                 gru_64[26][0]                    \n",
      "                                                                 gru_64[27][0]                    \n",
      "                                                                 gru_64[28][0]                    \n",
      "                                                                 gru_64[29][0]                    \n",
      "                                                                 gru_64[30][0]                    \n",
      "                                                                 gru_64[31][0]                    \n",
      "                                                                 gru_64[32][0]                    \n",
      "                                                                 gru_64[33][0]                    \n",
      "                                                                 gru_64[34][0]                    \n",
      "                                                                 gru_64[35][0]                    \n",
      "                                                                 gru_64[36][0]                    \n",
      "                                                                 gru_64[37][0]                    \n",
      "                                                                 gru_64[38][0]                    \n",
      "                                                                 gru_64[39][0]                    \n",
      "                                                                 gru_64[40][0]                    \n",
      "                                                                 gru_64[41][0]                    \n",
      "                                                                 gru_64[42][0]                    \n",
      "                                                                 gru_64[43][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32)           6176        batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_3[1][0]      \n",
      "                                                                 batch_normalization_3[2][0]      \n",
      "                                                                 batch_normalization_3[3][0]      \n",
      "                                                                 batch_normalization_3[4][0]      \n",
      "                                                                 batch_normalization_3[5][0]      \n",
      "                                                                 batch_normalization_3[6][0]      \n",
      "                                                                 batch_normalization_3[7][0]      \n",
      "                                                                 batch_normalization_3[8][0]      \n",
      "                                                                 batch_normalization_3[9][0]      \n",
      "                                                                 batch_normalization_3[10][0]     \n",
      "                                                                 batch_normalization_3[11][0]     \n",
      "                                                                 batch_normalization_3[12][0]     \n",
      "                                                                 batch_normalization_3[13][0]     \n",
      "                                                                 batch_normalization_3[14][0]     \n",
      "                                                                 batch_normalization_3[15][0]     \n",
      "                                                                 batch_normalization_3[16][0]     \n",
      "                                                                 batch_normalization_3[17][0]     \n",
      "                                                                 batch_normalization_3[18][0]     \n",
      "                                                                 batch_normalization_3[19][0]     \n",
      "                                                                 batch_normalization_3[20][0]     \n",
      "                                                                 batch_normalization_3[21][0]     \n",
      "                                                                 batch_normalization_3[22][0]     \n",
      "                                                                 batch_normalization_3[23][0]     \n",
      "                                                                 batch_normalization_3[24][0]     \n",
      "                                                                 batch_normalization_3[25][0]     \n",
      "                                                                 batch_normalization_3[26][0]     \n",
      "                                                                 batch_normalization_3[27][0]     \n",
      "                                                                 batch_normalization_3[28][0]     \n",
      "                                                                 batch_normalization_3[29][0]     \n",
      "                                                                 batch_normalization_3[30][0]     \n",
      "                                                                 batch_normalization_3[31][0]     \n",
      "                                                                 batch_normalization_3[32][0]     \n",
      "                                                                 batch_normalization_3[33][0]     \n",
      "                                                                 batch_normalization_3[34][0]     \n",
      "                                                                 batch_normalization_3[35][0]     \n",
      "                                                                 batch_normalization_3[36][0]     \n",
      "                                                                 batch_normalization_3[37][0]     \n",
      "                                                                 batch_normalization_3[38][0]     \n",
      "                                                                 batch_normalization_3[39][0]     \n",
      "                                                                 batch_normalization_3[40][0]     \n",
      "                                                                 batch_normalization_3[41][0]     \n",
      "                                                                 batch_normalization_3[42][0]     \n",
      "                                                                 batch_normalization_3[43][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1408)         0           dense2[0][0]                     \n",
      "                                                                 dense2[1][0]                     \n",
      "                                                                 dense2[2][0]                     \n",
      "                                                                 dense2[3][0]                     \n",
      "                                                                 dense2[4][0]                     \n",
      "                                                                 dense2[5][0]                     \n",
      "                                                                 dense2[6][0]                     \n",
      "                                                                 dense2[7][0]                     \n",
      "                                                                 dense2[8][0]                     \n",
      "                                                                 dense2[9][0]                     \n",
      "                                                                 dense2[10][0]                    \n",
      "                                                                 dense2[11][0]                    \n",
      "                                                                 dense2[12][0]                    \n",
      "                                                                 dense2[13][0]                    \n",
      "                                                                 dense2[14][0]                    \n",
      "                                                                 dense2[15][0]                    \n",
      "                                                                 dense2[16][0]                    \n",
      "                                                                 dense2[17][0]                    \n",
      "                                                                 dense2[18][0]                    \n",
      "                                                                 dense2[19][0]                    \n",
      "                                                                 dense2[20][0]                    \n",
      "                                                                 dense2[21][0]                    \n",
      "                                                                 dense2[22][0]                    \n",
      "                                                                 dense2[23][0]                    \n",
      "                                                                 dense2[24][0]                    \n",
      "                                                                 dense2[25][0]                    \n",
      "                                                                 dense2[26][0]                    \n",
      "                                                                 dense2[27][0]                    \n",
      "                                                                 dense2[28][0]                    \n",
      "                                                                 dense2[29][0]                    \n",
      "                                                                 dense2[30][0]                    \n",
      "                                                                 dense2[31][0]                    \n",
      "                                                                 dense2[32][0]                    \n",
      "                                                                 dense2[33][0]                    \n",
      "                                                                 dense2[34][0]                    \n",
      "                                                                 dense2[35][0]                    \n",
      "                                                                 dense2[36][0]                    \n",
      "                                                                 dense2[37][0]                    \n",
      "                                                                 dense2[38][0]                    \n",
      "                                                                 dense2[39][0]                    \n",
      "                                                                 dense2[40][0]                    \n",
      "                                                                 dense2[41][0]                    \n",
      "                                                                 dense2[42][0]                    \n",
      "                                                                 dense2[43][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1408)         5632        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 96)           135264      batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 96)           384         dense1[0][0]                     \n",
      "                                                                 dense1[1][0]                     \n",
      "                                                                 dense1[2][0]                     \n",
      "                                                                 dense1[3][0]                     \n",
      "                                                                 dense1[4][0]                     \n",
      "                                                                 dense1[5][0]                     \n",
      "                                                                 dense1[6][0]                     \n",
      "                                                                 dense1[7][0]                     \n",
      "                                                                 dense1[8][0]                     \n",
      "                                                                 dense1[9][0]                     \n",
      "                                                                 dense1[10][0]                    \n",
      "                                                                 dense1[11][0]                    \n",
      "                                                                 dense1[12][0]                    \n",
      "                                                                 dense1[13][0]                    \n",
      "                                                                 dense1[14][0]                    \n",
      "                                                                 dense1[15][0]                    \n",
      "                                                                 dense1[16][0]                    \n",
      "                                                                 dense1[17][0]                    \n",
      "                                                                 dense1[18][0]                    \n",
      "                                                                 dense1[19][0]                    \n",
      "                                                                 dense1[20][0]                    \n",
      "                                                                 dense1[21][0]                    \n",
      "                                                                 dense1[22][0]                    \n",
      "                                                                 dense1[23][0]                    \n",
      "                                                                 dense1[24][0]                    \n",
      "                                                                 dense1[25][0]                    \n",
      "                                                                 dense1[26][0]                    \n",
      "                                                                 dense1[27][0]                    \n",
      "                                                                 dense1[28][0]                    \n",
      "                                                                 dense1[29][0]                    \n",
      "                                                                 dense1[30][0]                    \n",
      "                                                                 dense1[31][0]                    \n",
      "                                                                 dense1[32][0]                    \n",
      "                                                                 dense1[33][0]                    \n",
      "                                                                 dense1[34][0]                    \n",
      "                                                                 dense1[35][0]                    \n",
      "                                                                 dense1[36][0]                    \n",
      "                                                                 dense1[37][0]                    \n",
      "                                                                 dense1[38][0]                    \n",
      "                                                                 dense1[39][0]                    \n",
      "                                                                 dense1[40][0]                    \n",
      "                                                                 dense1[41][0]                    \n",
      "                                                                 dense1[42][0]                    \n",
      "                                                                 dense1[43][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 1)            97          batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_5[1][0]      \n",
      "                                                                 batch_normalization_5[2][0]      \n",
      "                                                                 batch_normalization_5[3][0]      \n",
      "                                                                 batch_normalization_5[4][0]      \n",
      "                                                                 batch_normalization_5[5][0]      \n",
      "                                                                 batch_normalization_5[6][0]      \n",
      "                                                                 batch_normalization_5[7][0]      \n",
      "                                                                 batch_normalization_5[8][0]      \n",
      "                                                                 batch_normalization_5[9][0]      \n",
      "                                                                 batch_normalization_5[10][0]     \n",
      "                                                                 batch_normalization_5[11][0]     \n",
      "                                                                 batch_normalization_5[12][0]     \n",
      "                                                                 batch_normalization_5[13][0]     \n",
      "                                                                 batch_normalization_5[14][0]     \n",
      "                                                                 batch_normalization_5[15][0]     \n",
      "                                                                 batch_normalization_5[16][0]     \n",
      "                                                                 batch_normalization_5[17][0]     \n",
      "                                                                 batch_normalization_5[18][0]     \n",
      "                                                                 batch_normalization_5[19][0]     \n",
      "                                                                 batch_normalization_5[20][0]     \n",
      "                                                                 batch_normalization_5[21][0]     \n",
      "                                                                 batch_normalization_5[22][0]     \n",
      "                                                                 batch_normalization_5[23][0]     \n",
      "                                                                 batch_normalization_5[24][0]     \n",
      "                                                                 batch_normalization_5[25][0]     \n",
      "                                                                 batch_normalization_5[26][0]     \n",
      "                                                                 batch_normalization_5[27][0]     \n",
      "                                                                 batch_normalization_5[28][0]     \n",
      "                                                                 batch_normalization_5[29][0]     \n",
      "                                                                 batch_normalization_5[30][0]     \n",
      "                                                                 batch_normalization_5[31][0]     \n",
      "                                                                 batch_normalization_5[32][0]     \n",
      "                                                                 batch_normalization_5[33][0]     \n",
      "                                                                 batch_normalization_5[34][0]     \n",
      "                                                                 batch_normalization_5[35][0]     \n",
      "                                                                 batch_normalization_5[36][0]     \n",
      "                                                                 batch_normalization_5[37][0]     \n",
      "                                                                 batch_normalization_5[38][0]     \n",
      "                                                                 batch_normalization_5[39][0]     \n",
      "                                                                 batch_normalization_5[40][0]     \n",
      "                                                                 batch_normalization_5[41][0]     \n",
      "                                                                 batch_normalization_5[42][0]     \n",
      "                                                                 batch_normalization_5[43][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 44)           0           dense3[0][0]                     \n",
      "                                                                 dense3[1][0]                     \n",
      "                                                                 dense3[2][0]                     \n",
      "                                                                 dense3[3][0]                     \n",
      "                                                                 dense3[4][0]                     \n",
      "                                                                 dense3[5][0]                     \n",
      "                                                                 dense3[6][0]                     \n",
      "                                                                 dense3[7][0]                     \n",
      "                                                                 dense3[8][0]                     \n",
      "                                                                 dense3[9][0]                     \n",
      "                                                                 dense3[10][0]                    \n",
      "                                                                 dense3[11][0]                    \n",
      "                                                                 dense3[12][0]                    \n",
      "                                                                 dense3[13][0]                    \n",
      "                                                                 dense3[14][0]                    \n",
      "                                                                 dense3[15][0]                    \n",
      "                                                                 dense3[16][0]                    \n",
      "                                                                 dense3[17][0]                    \n",
      "                                                                 dense3[18][0]                    \n",
      "                                                                 dense3[19][0]                    \n",
      "                                                                 dense3[20][0]                    \n",
      "                                                                 dense3[21][0]                    \n",
      "                                                                 dense3[22][0]                    \n",
      "                                                                 dense3[23][0]                    \n",
      "                                                                 dense3[24][0]                    \n",
      "                                                                 dense3[25][0]                    \n",
      "                                                                 dense3[26][0]                    \n",
      "                                                                 dense3[27][0]                    \n",
      "                                                                 dense3[28][0]                    \n",
      "                                                                 dense3[29][0]                    \n",
      "                                                                 dense3[30][0]                    \n",
      "                                                                 dense3[31][0]                    \n",
      "                                                                 dense3[32][0]                    \n",
      "                                                                 dense3[33][0]                    \n",
      "                                                                 dense3[34][0]                    \n",
      "                                                                 dense3[35][0]                    \n",
      "                                                                 dense3[36][0]                    \n",
      "                                                                 dense3[37][0]                    \n",
      "                                                                 dense3[38][0]                    \n",
      "                                                                 dense3[39][0]                    \n",
      "                                                                 dense3[40][0]                    \n",
      "                                                                 dense3[41][0]                    \n",
      "                                                                 dense3[42][0]                    \n",
      "                                                                 dense3[43][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,115,746\n",
      "Trainable params: 3,109,282\n",
      "Non-trainable params: 6,464\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[sent_ids1,sentemb1], outputs=[out1]) #out\n",
    "model.load_weights('./model/att_clf/2ndStage_44fam_0611_copy1.h5',by_name=True) #改\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_gpu_model(model , gpus=2)\n",
    "\n",
    "# model.load_weights('./model/LSTM_att/1stStage_44fam_0607.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nsentemb1 = Input(shape=(max_length,emb_dim),name='sent_emb')\\nsentemb = Masking(mask_value=0)(sentemb1)\\nsent_ids1 = Input(shape=(max_length,), dtype='int32', name='sent_ids') # 輸入的api funvtion name ID\\nsent_ids = Masking(mask_value=0)(sent_ids1)\\napi_emb = Embedding(vocabulary_size+1, emb_dim,weights=[emb_matrix],input_length=max_length,trainable=True,name='api_emb')(sent_ids)\\n\\nfinal_emb = Add()([sentemb,api_emb])\\n\\ntimesteps,state_h,state_c = LSTM(int(emb_dim/2),return_sequences=True,return_state=True,name='lstm1')(final_emb) #final_emb\\nstate = Concatenate()([state_h,state_c])\\nfc = Dense(max_length,activation='sigmoid',bias_constraint=None,kernel_initializer=init,name='attention')(state)\\nfc = Lambda(lambda x: keras.backend.expand_dims(x,axis=-1),name='RasMMA')(fc)\\nfc = Lambda(lambda x: keras.backend.repeat_elements(x,int(emb_dim/2),axis=-1))(fc)\\n# fc = keras.backend.repeat_elements(fc,256,axis=-1)\\n# fc = keras.backend.expand_dims(fc,axis=-1)\\nmul = Multiply()([fc,timesteps])\\n# mul = BatchNormalization()(mul)\\nalls = []\\ngru = (GRU(int(emb_dim/4))) #/8\\n# gru = GRU(1)\\nbn = BatchNormalization()\\ndp = Dropout(0.01)\\n\\ndense = Dense(1,activation='sigmoid')\\nfor i in range(fam_num):\\n#     alls.append(dense(bn(gru(mul))))\\n    alls.append(dense(dp(bn(gru(mul)))))\\n#     alls.append(gru(mul))\\nout = Concatenate(name='family')(alls)\\n# out = Dense(44,activation='sigmoid')(out)\\nmodel_old = Model(inputs=[sent_ids1,sentemb1], outputs=[out]) #out\\nmodel_old = multi_gpu_model(model_old , gpus=3)\\nmodel_old.load_weights('./model/LSTM_att/1stStage_44fam_0607.h5')\\nmodel_old.summary()\\n\\n# model = load_model('./model/LSTM_att/1stStage_44fam_0607.h5_all.h5')\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "sentemb1 = Input(shape=(max_length,emb_dim),name='sent_emb')\n",
    "sentemb = Masking(mask_value=0)(sentemb1)\n",
    "sent_ids1 = Input(shape=(max_length,), dtype='int32', name='sent_ids') # 輸入的api funvtion name ID\n",
    "sent_ids = Masking(mask_value=0)(sent_ids1)\n",
    "api_emb = Embedding(vocabulary_size+1, emb_dim,weights=[emb_matrix],input_length=max_length,trainable=True,name='api_emb')(sent_ids)\n",
    "\n",
    "final_emb = Add()([sentemb,api_emb])\n",
    "\n",
    "timesteps,state_h,state_c = LSTM(int(emb_dim/2),return_sequences=True,return_state=True,name='lstm1')(final_emb) #final_emb\n",
    "state = Concatenate()([state_h,state_c])\n",
    "fc = Dense(max_length,activation='sigmoid',bias_constraint=None,kernel_initializer=init,name='attention')(state)\n",
    "fc = Lambda(lambda x: keras.backend.expand_dims(x,axis=-1),name='RasMMA')(fc)\n",
    "fc = Lambda(lambda x: keras.backend.repeat_elements(x,int(emb_dim/2),axis=-1))(fc)\n",
    "# fc = keras.backend.repeat_elements(fc,256,axis=-1)\n",
    "# fc = keras.backend.expand_dims(fc,axis=-1)\n",
    "mul = Multiply()([fc,timesteps])\n",
    "# mul = BatchNormalization()(mul)\n",
    "alls = []\n",
    "gru = (GRU(int(emb_dim/4))) #/8\n",
    "# gru = GRU(1)\n",
    "bn = BatchNormalization()\n",
    "dp = Dropout(0.01)\n",
    "\n",
    "dense = Dense(1,activation='sigmoid')\n",
    "for i in range(fam_num):\n",
    "#     alls.append(dense(bn(gru(mul))))\n",
    "    alls.append(dense(dp(bn(gru(mul)))))\n",
    "#     alls.append(gru(mul))\n",
    "out = Concatenate(name='family')(alls)\n",
    "# out = Dense(44,activation='sigmoid')(out)\n",
    "model_old = Model(inputs=[sent_ids1,sentemb1], outputs=[out]) #out\n",
    "model_old = multi_gpu_model(model_old , gpus=3)\n",
    "model_old.load_weights('./model/LSTM_att/1stStage_44fam_0607.h5')\n",
    "model_old.summary()\n",
    "\n",
    "# model = load_model('./model/LSTM_att/1stStage_44fam_0607.h5_all.h5')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_old.layers[-2].save_weights('./model/LSTM_att/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_multi_label_metric(y_true, y_pred):\n",
    "    comp = K.equal(y_true, K.round(y_pred))\n",
    "    return K.cast(K.all(comp, axis=-1), K.floatx())\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
    "               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "def custom_acc1(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred,k=3)\n",
    "from keras.metrics import binary_accuracy\n",
    "def bin_acc(y_true, y_pred):\n",
    "    return binary_accuracy(y_true, y_pred)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    return tf.keras.metrics.Precision(y_true,y_pred)[1]\n",
    "def recall(y_true, y_pred):\n",
    "    return tf.keras.metrics.Recall(y_true,y_pred)[1]\n",
    "def Hamming_loss(y_true, y_pred):\n",
    "    tmp = K.abs(y_true-y_pred)\n",
    "    return K.mean(K.cast(K.greater(tmp,0.5),dtype=float))\n",
    "def hn_multilabel_loss(y_true, y_pred):\n",
    "    # Avoid divide by 0\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Multi-task loss\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))\n",
    "# from sklearn.metrics import f1_score\n",
    "# def f1_sk(y_true,y_pred):\n",
    "#     score = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "#     return score\n",
    "\n",
    "# 訓練參數\n",
    "los = [losses.binary_crossentropy,binary_focal_loss(alpha=.25, gamma=2)] # 1st stage.  f1_loss\n",
    "#SINGLE\n",
    "los = [binary_focal_loss(alpha=.25, gamma=2)] #改\n",
    "los = [hn_multilabel_loss]\n",
    "# los = [losses.binary_crossentropy]\n",
    "# MML\n",
    "'''los = []\n",
    "for i in range(fam_num):\n",
    "    los.append(binary_focal_loss(alpha=.25, gamma=2))\n",
    "los = [losses.binary_crossentropy] + los'''\n",
    "\n",
    "\n",
    "metric = {'RasMMA': 'acc','family': f1} # 1st stage. km.f1_score()\n",
    "#SINGLE\n",
    "metric = [f1_metric,bin_acc]\n",
    "# metric = [km.f1_score(),bin_acc,km.binary_f1_score()]\n",
    "# metric = {'RasMMA': 'acc'}\n",
    "# metric = [bin_acc] #改\n",
    "#MML\n",
    "'''metrics = []\n",
    "for i in range(fam_num+1):\n",
    "    metrics.append('acc')\n",
    "# metrics = {}\n",
    "# metrics['RasMMA'] = 'acc'\n",
    "# for i in range(fam_num):\n",
    "#     metrics['fam'+str(i)]='acc'\n",
    "metric = metrics'''\n",
    "\n",
    "\n",
    "loss_weight = [1,1] #stage1 0.95,0.05  #1st stage # 2nd stage [0.01,0.99]\n",
    "#SINGLE\n",
    "loss_weight = [1]\n",
    "#MML\n",
    "'''loss_weight = []\n",
    "for i in range(fam_num):\n",
    "    loss_weight.append(0.95)\n",
    "loss_weight = [0.05] + loss_weight'''\n",
    "\n",
    "learning_rate = 5e-4#2e-4 # 2nd stage: 1e-4 @1st:2e-4 0.002\n",
    "# batch_size = 128 #32 #128\n",
    "\n",
    "num_epochs = 1000\n",
    "patien = 50\n",
    "\n",
    "model_save_path = './model/att_clf/3rdStage_44fam_0611_copy1.h5' #改\n",
    "tensorboard_log_path = './logs/'+ model_save_path.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "optimizer = optimizers.Adam(\n",
    "            lr=learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False) #clipnorm=1. , clipvalue=1.\n",
    "optimizer = keras.optimizers.Nadam(lr=learning_rate, clipvalue=1.) #改\n",
    "# tf.keras.optimizers.Nadam\n",
    "lr_scheduler1 = callbacks.LearningRateScheduler(\n",
    "        CosineLRSchedule(lr_high=0.0006, lr_low=1e-8, #learning_rate #改\n",
    "                         initial_period=num_epochs),\n",
    "        verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=int(patien/3),\n",
    "                                      min_lr=1e-8,mode='min')\n",
    "\n",
    "model.compile(\n",
    "            optimizer,\n",
    "            loss=los,\n",
    "            metrics=metric ,loss_weights=loss_weight)#{'word_predictions': masked_perplexity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best, early stopping, 2 models ens weight:(best=0.8,last=0.2)\n",
    "history = History()\n",
    "stop_nan = callbacks.TerminateOnNaN()\n",
    "model_callbacks = [\n",
    "        callbacks.ModelCheckpoint(\n",
    "            model_save_path, #val_f1_metric,max\n",
    "            monitor='val_loss',mode='min' ,save_best_only=True, verbose=1,save_weights_only=True), #改\n",
    "            EarlyStopping(patience=patien,monitor='val_loss',verbose=1,mode='min'),\n",
    "        lr_scheduler, lr_scheduler1,history,stop_nan\n",
    "    ]\n",
    "model_callbacks.append(callbacks.TensorBoard(tensorboard_log_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_batch(batch_size, X_train1, X_train2 , Y_train1, Y_train2):\n",
    "    '''\n",
    "    X_train1 = sent_ids: shape為(N, max_seq_length)\n",
    "    X_train2 = sentemb: shape為(N,max_seq_length, word_embedding_size)\n",
    "    Y_train1 = class_prediction: shape為(N, max_seq_length, 1)\n",
    "    Y_train2 = family_prediction(stage2): shape為(N, fam_num)\n",
    "    '''\n",
    "    idx = np.arange(len(X_train1))\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    while True:\n",
    "        for i in idx:\n",
    "            train_X1 = X_train1[idx[i]:idx[i]+batch_size]\n",
    "            train_X2 = X_train2[idx[i]:idx[i]+batch_size]\n",
    "            train_Y1 = Y_train1[idx[i]:idx[i]+batch_size]\n",
    "            train_Y2 = Y_train2[idx[i]:idx[i]+batch_size]\n",
    "#             yield(train_X2,train_Y2)\n",
    "#             yield ([train_X1,train_X2],[train_Y1,train_Y2]) #ori\n",
    "            yield ([train_X1,train_X2],[train_Y2]) #改\n",
    "            if i == idx[-1]:\n",
    "                idx = np.arange(len(X_train1))\n",
    "                np.random.shuffle(idx)\n",
    "                break\n",
    "            \n",
    "#     data_size = X_train.shape[0]\n",
    "#     ep = data_size / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leoqaz12/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/leoqaz12/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoqaz12/.local/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0006.\n",
      "135/175 [======================>.......] - ETA: 10:10 - loss: 55.4248 - f1_metric: 0.0326 - bin_acc: 0.8465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/leoqaz12/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-823ff74700f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0;34m,\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfam_weights\u001b[0m \u001b[0;31m#改\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                    ,shuffle=True,verbose=1)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_all.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#1st:train 0_1_prediction=0.14XX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "H = model.fit_generator(\n",
    "    generator=training_batch(batch_size=batch_size,X_train1=train_emb_api,X_train2=train_emb ,\n",
    "                                             Y_train1=train_rep_ans,Y_train2=train_fam_ans) #Y_train2\n",
    "#                     generator=training_batch(batch_size=batch_size,X_train1=valid_emb_api,X_train2=valid_emb ,\n",
    "#                                              Y_train1=train_rep_ans,Y_train2=train_fam_ans)\n",
    "                        , steps_per_epoch=int(np.ceil(len(train_emb_api)/batch_size)) ,\n",
    "                    epochs=num_epochs,callbacks=model_callbacks\n",
    "#                    ,validation_data= ([valid_emb_api,valid_emb], [valid_rep_ans,valid_fam_ans]) #ori\n",
    "#                    ,validation_data= (valid_emb, valid_fam_ans) \n",
    "                   ,validation_data= ([valid_emb_api,valid_emb], [valid_fam_ans]) #ori #改\n",
    "#                    ,validation_data= ([valid_emb_api,valid_emb], [valid_rep_ans]+valid_Y2) #validY2\n",
    "                    ,max_queue_size=10  ,class_weight=fam_weights #改\n",
    "                    ,workers=10,use_multiprocessing=True   \n",
    "                   ,shuffle=True,verbose=1)\n",
    "model.save(model_save_path+\"_all.h5\")\n",
    "#1st:train 0_1_prediction=0.14XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "* multi model weights 儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-faba7497f628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorboard_log_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'H.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_weights(model_save_path)\n",
    "model_ = model.layers[-2]\n",
    "model_.save_weights(model_save_path)\n",
    "model_.summary()\n",
    "pickle.dump(file=open(tensorboard_log_path + '/'+'H.pkl','wb'),obj=H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json, model_from_yaml\n",
    "json_string = model.to_json()\n",
    "yaml_string = model.to_yaml()\n",
    "pickle.dump(file=open(tensorboard_log_path + '/'+'arch.pkl','wb'),obj=(json_string,yaml_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_weights('./model/LSTM_att/1stStage_44fam_0610.h5')\n",
    "# model.load_weights('./model/att_clf/1stStage_44fam_0611_copy1.h5')\n",
    "# score = model.evaluate([valid_emb_api,valid_emb], [valid_rep_ans]+valid_Y2)\n",
    "print(len(test_emb_api)) #改\n",
    "ans = model.predict([test_emb_api,test_emb]) #改\n",
    "y_true = test_fam_ans #改\n",
    "# ans = model.predict([valid_emb_api,valid_emb])\n",
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rep_ans[113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_.save_weights('./model/LSTM_att/test4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.41569626],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ],\n",
       "       [0.2488809 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ = model.layers[-2]\n",
    "layer_name = 'lambda_1' #lambda_1 multiply_1  #9~12\n",
    "intermediate_layer_model = Model(inputs=model_.inputs,\n",
    "                                 outputs=model_.layers[9].output)\n",
    "intermediate_output = intermediate_layer_model.predict([valid_emb_api,valid_emb])\n",
    "intermediate_output[113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[260.19174],\n",
       "       [260.01572],\n",
       "       [260.1888 ],\n",
       "       [259.98257],\n",
       "       [259.78748],\n",
       "       [260.16696],\n",
       "       [260.1548 ],\n",
       "       [260.1669 ],\n",
       "       [260.18207],\n",
       "       [260.19427],\n",
       "       [260.15488],\n",
       "       [259.25223],\n",
       "       [259.4004 ],\n",
       "       [259.08444],\n",
       "       [258.34335],\n",
       "       [257.66986],\n",
       "       [257.55835],\n",
       "       [255.35646],\n",
       "       [255.08438],\n",
       "       [255.22533],\n",
       "       [250.46489],\n",
       "       [252.74919],\n",
       "       [245.37274],\n",
       "       [246.13077],\n",
       "       [242.22926],\n",
       "       [243.88678],\n",
       "       [242.69434],\n",
       "       [241.57124],\n",
       "       [240.4437 ],\n",
       "       [238.97427],\n",
       "       [238.19403],\n",
       "       [238.97964],\n",
       "       [236.31757],\n",
       "       [235.90297],\n",
       "       [235.66853],\n",
       "       [230.89377],\n",
       "       [224.76675],\n",
       "       [224.65862],\n",
       "       [222.63896],\n",
       "       [223.42125],\n",
       "       [222.64436],\n",
       "       [221.05728],\n",
       "       [220.1669 ],\n",
       "       [220.10486],\n",
       "       [219.12794],\n",
       "       [221.31013],\n",
       "       [218.81532],\n",
       "       [219.0352 ],\n",
       "       [217.81775],\n",
       "       [216.09543],\n",
       "       [214.13669],\n",
       "       [214.32732],\n",
       "       [204.96117],\n",
       "       [202.90384],\n",
       "       [212.1658 ],\n",
       "       [211.40784],\n",
       "       [201.9294 ],\n",
       "       [202.09953],\n",
       "       [210.6589 ],\n",
       "       [211.31676],\n",
       "       [211.05814],\n",
       "       [210.63927],\n",
       "       [210.34561],\n",
       "       [209.77522],\n",
       "       [208.7014 ],\n",
       "       [206.41469],\n",
       "       [207.14885],\n",
       "       [207.45335],\n",
       "       [206.18121],\n",
       "       [204.3603 ],\n",
       "       [203.14037],\n",
       "       [202.90866],\n",
       "       [200.91515],\n",
       "       [201.69136],\n",
       "       [200.91063],\n",
       "       [201.57063],\n",
       "       [198.44092],\n",
       "       [199.22133],\n",
       "       [198.1393 ],\n",
       "       [199.22597],\n",
       "       [198.44542],\n",
       "       [198.92093],\n",
       "       [198.3995 ],\n",
       "       [197.7813 ],\n",
       "       [197.19493],\n",
       "       [198.47295],\n",
       "       [197.43506],\n",
       "       [197.39734],\n",
       "       [195.80708],\n",
       "       [196.58762],\n",
       "       [195.80708],\n",
       "       [196.01591],\n",
       "       [187.61694],\n",
       "       [186.4031 ],\n",
       "       [184.63313],\n",
       "       [184.38185],\n",
       "       [181.38632],\n",
       "       [181.76503],\n",
       "       [181.3137 ],\n",
       "       [177.61305],\n",
       "       [177.35287],\n",
       "       [177.7562 ],\n",
       "       [175.2605 ],\n",
       "       [176.04103],\n",
       "       [176.0453 ],\n",
       "       [163.57327],\n",
       "       [161.23401],\n",
       "       [150.73936],\n",
       "       [150.11197],\n",
       "       [149.47763],\n",
       "       [149.12497],\n",
       "       [149.19858],\n",
       "       [148.41805],\n",
       "       [149.19858],\n",
       "       [148.2963 ],\n",
       "       [147.81886],\n",
       "       [148.80588],\n",
       "       [148.80588],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [147.24716],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [147.24716],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [148.23416],\n",
       "       [146.8749 ],\n",
       "       [146.8749 ],\n",
       "       [145.51561],\n",
       "       [145.51561],\n",
       "       [145.51561],\n",
       "       [144.7409 ],\n",
       "       [144.7409 ],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [144.13547],\n",
       "       [143.74718],\n",
       "       [143.74718],\n",
       "       [142.7359 ],\n",
       "       [142.05388],\n",
       "       [142.05388],\n",
       "       [142.05388],\n",
       "       [142.05388],\n",
       "       [142.05388],\n",
       "       [142.05388],\n",
       "       [138.50333],\n",
       "       [138.50333],\n",
       "       [138.50333],\n",
       "       [138.68404],\n",
       "       [139.46457],\n",
       "       [137.31866],\n",
       "       [137.31866],\n",
       "       [137.31866],\n",
       "       [137.31866],\n",
       "       [137.31866],\n",
       "       [137.31866],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.49939],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011],\n",
       "       [137.68011]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(intermediate_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output[113].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output[100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sent_ids (InputLayer)           (None, 213)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sent_emb (InputLayer)           (None, 213, 768)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 213)          0           sent_ids[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 213, 768)     0           sent_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 213)          0           sent_ids[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 213, 768)     0           sent_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 44)           3115746     lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 44)           0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,115,746\n",
      "Trainable params: 3,109,282\n",
      "Non-trainable params: 6,464\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_.summary() #multiply_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 44) 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "# y_true = np.squeeze(test_fam_ans)\n",
    "# y_true = np.squeeze(valid_fam_ans1)\n",
    "# y_pred = np.squeeze(predict_fam)\n",
    "final_ans = []\n",
    "for sample in ans:\n",
    "    sample_ans = []\n",
    "    for value in sample:\n",
    "        if value < 0.2:\n",
    "            sample_ans.append(0)\n",
    "        else:\n",
    "            sample_ans.append(1)\n",
    "    final_ans.append(sample_ans)\n",
    "final_ans = np.array(final_ans)\n",
    "print(final_ans.shape , sum(final_ans[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 44) (424, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6, 0.32035532620578944, 0.38563788635500984)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_true = test_fam_ans\n",
    "print(y_true.shape , final_ans.shape)\n",
    "recall = recall_score(y_true=y_true, y_pred=final_ans, average='weighted')\n",
    "precision = precision_score(y_true=y_true, y_pred=final_ans, average='weighted')\n",
    "f1 = f1_score(y_true=y_true, y_pred=final_ans, average='weighted')\n",
    "recall ,precision, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
