{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RasMMA usage\n",
    "Usage of RasMMA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do clustering and output two pickle files. (@_intermediate.pickle and @_nameDict.pickle)\n",
    "% run RasMMA.ipynb\n",
    "import os\n",
    "\n",
    "def startClustering(data_directory, tag, outputPath, thresholdValue=None):\n",
    "    if not os.listdir(data_directory):\n",
    "        print(\"Data Empty\")\n",
    "        return\n",
    "    \n",
    "    # Create Directories if didn't exist\n",
    "    if not os.path.isdir(outputPath): os.makedirs(outputPath)\n",
    "    pickleDir = outputPath + \"pickle/\"\n",
    "    if not os.path.isdir(pickleDir): os.makedirs(pickleDir)\n",
    "        \n",
    "    # link RasMMA algorithm logic\n",
    "    intermediatePool, initialDict, roundInfos, residual = do_RasMMA_clustering(data_directory,\n",
    "                                                                               tag,\n",
    "                                                                               outputPath,\n",
    "                                                                               thresholdValue)\n",
    "\n",
    "    # saving intermediatePool as pickle file\n",
    "    with open(pickleDir + tag + '_intermediate.pickle', 'wb') as handle:\n",
    "        pickle.dump(intermediatePool, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # saving initialNames dict as pickle file\n",
    "    with open(pickleDir + tag + '_initialDict.pickle', 'wb') as handle:\n",
    "        pickle.dump(initialDict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # saving round information dict as pickle file\n",
    "    with open(pickleDir + tag + '_roundInfos.pickle', 'wb') as handle:\n",
    "        pickle.dump(roundInfos, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    if(residual is not None):\n",
    "        # saving round information dict as pickle file\n",
    "        with open(pickleDir + tag + '_residual.pickle', 'wb') as handle:\n",
    "            pickle.dump(residual, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Cell\n",
    "usage example of get clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-Sep-21 15:08\n",
      "-- Finish Initializing --\n",
      "-- Start Clustering --\n",
      "Threshold set = 0.8\n",
      "Round:  1\n"
     ]
    }
   ],
   "source": [
    "# basic global inputs variable\n",
    "def main(data_directory, tag, outputPath, manualThresholdNumber):\n",
    "    import datetime\n",
    "    date_time = datetime.datetime.now()\n",
    "    print(date_time.strftime(\"%Y-%b-%d %H:%M\"))\n",
    "    startClustering(data_directory, tag, outputPath, manualThresholdNumber)\n",
    "    date_time = datetime.datetime.now()\n",
    "    print(date_time.strftime(\"%Y-%b-%d %H:%M\"))\n",
    "\n",
    "\n",
    "manualThresholdNumber = 0.8 # defined the threshold of merge score\n",
    "familyName = \"1.allaple\"\n",
    "data_directory = \"data/aries_simplified/\"+ familyName +\"/\" # data trace directory\n",
    "tag = familyName + \"_0.8\" # used for naming pickle\n",
    "outputPath = \"output/RasMMA_forest/\" + tag + \"/\"\n",
    "pickleDir = outputPath + \"pickle/\"\n",
    "\n",
    "main(data_directory, tag, outputPath, manualThresholdNumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RasMMA in Multi-processes for Aries_V2_simplified_15up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualThresholdNumber = 0.8 # defined the threshold of merge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from multiprocessing import Pool, Manager\n",
    "\n",
    "extract_family_range = [1, 15] # set family ID range you want to run rasMMA\n",
    "family_folder_path = '/home/master/r07725027/dataset/aries_v2_simplified_15up' # change to your dataset path\n",
    "output_path_root = \"/home/master/r07725027/dataset/rasMMA-output\" # change to output path\n",
    "pickle_dir = ''\n",
    "\n",
    "families = os.listdir(family_folder_path)\n",
    "\n",
    "# return family directory within range\n",
    "def get_family_names():\n",
    "    family_names = []\n",
    "    for family in families:\n",
    "        (family_num, family_name) = family.split('.')\n",
    "        family_num = int(family_num)\n",
    "\n",
    "        if extract_family_range[0] <= family_num <= extract_family_range[1]:\n",
    "            family_names.append(family)\n",
    "            \n",
    "    return family_names\n",
    "\n",
    "# extract function for multiprocessing\n",
    "def extract(family_name, error_messages):\n",
    "    global pickle_dir\n",
    "    \n",
    "    data_directory = f'{family_folder_path}/{family_name}/'\n",
    "    tag = family_name.split('.')[1] + \"_0.8\" # used for naming pickle\n",
    "    output_path = f'{output_path_root}/{tag}/'\n",
    "    pickle_dir = f'{output_path}pickle/'\n",
    "    \n",
    "    try:\n",
    "        main(data_directory, tag, output_path, manualThresholdNumber)\n",
    "    except Exception as e:\n",
    "        error_type = sys.exc_info()[0]\n",
    "        error = str(e)\n",
    "        print('Error: ' + family_name, type(e).__name__, ': ', error)\n",
    "        error_messages.put(f'{tag} -> {type(e).__name__}: {error}')\n",
    "    \n",
    "\n",
    "def main_extract():\n",
    "    # shared memory error list between processes\n",
    "    manager = Manager()\n",
    "    error_messages = manager.Queue()\n",
    "\n",
    "    # use multiprocess\n",
    "    with Pool(processes = 15) as pool: # define how many processes to run\n",
    "        # use starmap to map job to process, and pass multiple args to extract function\n",
    "        pool.starmap(extract, [(family, error_messages) for family in get_family_names()])\n",
    "    \n",
    "    print('\\n----- Error Messages -----')\n",
    "    while error_messages.empty() is False:\n",
    "        print(error_messages.get())\n",
    "        \n",
    "main_extract()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below cell used to write csv - _groupInfo, _decendants, _motifs\n",
    "groupInfo.csv can see merge score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if familyName:\n",
    "    familyName = familyName\n",
    "else:\n",
    "    familyName = \"berbew\"\n",
    "if tag:\n",
    "    tag = tag\n",
    "else:\n",
    "    tag = familyName+\"_0.8\" # used for pickle name\n",
    "if outputPath:\n",
    "    outputPath = outputPath\n",
    "else:\n",
    "    outputPath = \"output/RasMMA_forest/\" + tag + \"/\"\n",
    "if pickleDir:\n",
    "    pickleDir = pickleDir\n",
    "else:\n",
    "    pickleDir = outputPath + \"pickle/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# read the results from pickle files\n",
    "with open(pickleDir + tag + '_intermediate.pickle', 'rb') as handle:\n",
    "    intermediate = pickle.load(handle)\n",
    "with open(pickleDir + tag + '_initialDict.pickle', 'rb') as handle:\n",
    "    initialDict = pickle.load(handle)\n",
    "with open(pickleDir + tag + '_roundInfos.pickle', 'rb') as handle:\n",
    "    roundInfos = pickle.load(handle)\n",
    "    \n",
    "# calculate motif lengths of all common motifs\n",
    "def getMotifsLengthList(motifs):\n",
    "    motifLens = list()\n",
    "    for motif in motifs:\n",
    "        mLen = len(motif)\n",
    "        motifLens.append(mLen)\n",
    "    return motifLens\n",
    "\n",
    "def findGeneratedRoundNumber(clusterName, roundInfosDict):\n",
    "    for key, value in roundInfosDict.items():\n",
    "        if clusterName in value:\n",
    "            return key\n",
    "    return -1\n",
    "\n",
    "import csv\n",
    "\n",
    "descendant_dict = dict()\n",
    "groupInfo_list = list()\n",
    "groupMotif_dict = dict()\n",
    "\n",
    "intermediate_list = sorted(intermediate.items(), key=lambda x : x[0])\n",
    "for item in intermediate_list:\n",
    "    value = item[1] # get original dict value\n",
    "    score = value[0]\n",
    "    clusterName = value[1][0]\n",
    "    memberSet = value[2]\n",
    "    motifs = value[1][1]\n",
    "    \n",
    "    # calculate motif lengths of all common motifs\n",
    "    motifsLens = getMotifsLengthList(motifs) # is a list of numbers\n",
    "    totalMotifLen = sum(motifsLens) # sum the list\n",
    "\n",
    "    motifsCount = len(motifs)\n",
    "    \n",
    "    descendants = set()\n",
    "    for member in memberSet:\n",
    "        if member[0] == \"G\":\n",
    "            for descendant in descendant_dict[member]:\n",
    "                descendants.add(descendant)\n",
    "        else:\n",
    "            descendants.add(member)\n",
    "        \n",
    "    descendant_dict[clusterName] = descendants\n",
    "    \n",
    "    \n",
    "    groupMotif_dict[clusterName] = motifs\n",
    "    roundNumber = findGeneratedRoundNumber(clusterName, roundInfos)\n",
    "    groupInfo_list.append((roundNumber, clusterName, score, memberSet, motifsCount, motifsLens, totalMotifLen))\n",
    "\n",
    "with open(pickleDir + tag + \"_descendant.pickle\", 'wb') as f:\n",
    "    pickle.dump(descendant_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# write file \"GroupInfo.csv\" :  clusterName, score, members, motifCount, common motifs length list\n",
    "with open(outputPath + tag + \"_GroupInfo.csv\", 'w', newline='') as infoFile:\n",
    "    spamwriter = csv.writer(infoFile, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    header = [\"Round\", \"ClusterName\", \"SimilarityScore\", \"Members\", \"MotifsCount\", \"Motifs_Length\", \"Total_MotifLength\"]\n",
    "    spamwriter.writerow(header)\n",
    "    \n",
    "    # write initial cluster informations(i.e., hooklogs)\n",
    "    for key in sorted(initialDict.keys(), key = lambda x : int(x[1::])):\n",
    "        # something like this: (0, \"G1\", \"N/A\", \"abc\", 1, 109)\n",
    "        originDataRow = (0, key, \"N/A\", initialDict[key][0], 1, initialDict[key][1], initialDict[key][1])\n",
    "        spamwriter.writerow(originDataRow)\n",
    "        \n",
    "    # write cluster informations\n",
    "    for group in groupInfo_list:\n",
    "        spamwriter.writerow(group)\n",
    "        \n",
    "with open(outputPath + tag + \"_Descendants.csv\", \"w\", newline='') as descFile:\n",
    "    spamwriter = csv.writer(descFile, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    header = [\"ClusterName\", \"Descendant Counts\", \"Descendants\"]\n",
    "    spamwriter.writerow(header)\n",
    "    for key in sorted(descendant_dict.keys(), key = lambda x : int(x[1::])):\n",
    "        row = (key, len(descendant_dict[key]), descendant_dict[key])\n",
    "        spamwriter.writerow(row)\n",
    "        \n",
    "# write file \"Motifs.csv\" :  clusterName, MotifNumber, apis\n",
    "with open(outputPath + tag + \"_Motifs.csv\", 'w', newline='', encoding='utf-8') as motifFile:\n",
    "    spamwriter = csv.writer(motifFile, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    header = [\"ClusterName\", \"MotifIndex\", \"MotifLength\", \"Common Motif APIs\"]\n",
    "    spamwriter.writerow(header)\n",
    "\n",
    "    for key in sorted(groupMotif_dict.keys(), key = lambda x : int(x[1::])):\n",
    "        group_motifs = groupMotif_dict[key]\n",
    "        motifIdx = 0\n",
    "        for motif in group_motifs:\n",
    "            firstMotifAPI = True\n",
    "            motifLen = len(motif)\n",
    "            for api in motif:\n",
    "                if(firstMotifAPI):\n",
    "                    row = (key, motifIdx, motifLen, api)\n",
    "                    firstMotifAPI = False\n",
    "                else:\n",
    "                    row = (\"\", \"\", \"\", api)\n",
    "                spamwriter.writerow(row)\n",
    "            motifIdx += 1\n",
    "            \n",
    "# output residual information of SBBGCA\n",
    "\n",
    "with open(pickleDir + tag + '_residual.pickle', 'rb') as handle:\n",
    "    residual = pickle.load(handle)\n",
    "    \n",
    "with open(outputPath + tag + \"_GroupInfo.csv\", 'a', newline='') as expandGroupInfo:\n",
    "    spamwriter = csv.writer(expandGroupInfo, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    header = [\"ClusterName\", \"Members\", \"MotifLength\"]\n",
    "    \n",
    "    spamwriter.writerow(\"\")\n",
    "    spamwriter.writerow((\"Residual Clusters:\",\"\",\"\"))\n",
    "    spamwriter.writerow(header)\n",
    "    \n",
    "    for key, value in residual.items():\n",
    "        clusterName = value[0][0]\n",
    "        motifsList = value[0][1]\n",
    "        motifLens = getMotifsLengthList(motifsList)\n",
    "        members = value[1]\n",
    "        if( len(members) == 0 ):\n",
    "            row = (clusterName, \"N/A\", motifLens)\n",
    "        else:\n",
    "            row = (clusterName, members, motifLens)\n",
    "            \n",
    "        spamwriter.writerow(row)\n",
    "print(familyName,'Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show merge pairs in RasMMA to draw behavior forest\n",
    "if someone need to draw behavior forest for visualization, Need manual.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reverse clusterID by hooklogName\n",
    "def findClusterID(nameDict, hooklogName):\n",
    "    for key, value in nameDict.items():\n",
    "        if(value == hooklogName):\n",
    "            return key\n",
    "    return hooklogName\n",
    "\n",
    "def getInitialNameDict(initialDict):\n",
    "    nameDict = dict()\n",
    "    for key, value in initialDict.items():\n",
    "        name = value[0]\n",
    "        nameDict[key] = name\n",
    "    return nameDict\n",
    "\n",
    "# z[0] = g1,  z[1] = g2,  z[2] = 高度\n",
    "# Create structure Z\n",
    "\n",
    "def createStructZ(intermediate_dict, nameDict):\n",
    "    import numpy as np\n",
    "    Z = np.zeros((len(intermediate_dict)+1 ,4))\n",
    "    intermediate_list = sorted(intermediate_dict.items(), key=lambda x:x[0])\n",
    "    iterCounter = 0\n",
    "    \n",
    "    for item in intermediate_list:\n",
    "        value = item[1] # get original dict value\n",
    "        score = value[0]\n",
    "        height = 1 - score # get cluster distance\n",
    "        clusterName = value[1][0]\n",
    "        memberSet = value[2] # members set\n",
    "        memberList = getMemberList(memberSet, nameDict)\n",
    "        print(clusterName,\" : \", score,\" - \", memberList)\n",
    "        member1 = memberList[0][1::]\n",
    "        member2 = memberList[-1][1::]\n",
    "        Z[iterCounter] = [member1, member2, height, len(memberList)] # set Z element\n",
    "        iterCounter+=1\n",
    "\n",
    "    return Z\n",
    "\n",
    "# convert memberSet to List type\n",
    "\n",
    "def getMemberList(memberSet, nameDict):\n",
    "    memberList = list()\n",
    "    while(len(memberSet)>0):\n",
    "        member = memberSet.pop()\n",
    "        clusterID = findClusterID(nameDict, member)\n",
    "        memberList.append(clusterID)\n",
    "    return memberList\n",
    "\n",
    "def createLabelList(nameDict):\n",
    "    dict_keys = list(nameDict.keys())\n",
    "    dict_keys.sort(key=lambda tup: int(tup[1::] )) # sort keys by number in clusterName (i.e., '31' in 'G31')\n",
    "    \n",
    "    labelList = list()\n",
    "    for key in dict_keys:\n",
    "        labelList.append( nameDict[key] )\n",
    "    \n",
    "    return labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw pics\n",
    "def drawClusteringResults(picklePath, outputPath, tag, upgma_threshold):\n",
    "    \n",
    "    #     Dependencies\n",
    "    import pickle\n",
    "    import scipy\n",
    "    import scipy.cluster.hierarchy as sch\n",
    "    import matplotlib.pylab as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    # read the results from pickle files\n",
    "    with open(picklePath + tag + '_intermediate.pickle', 'rb') as handle:\n",
    "        intermediate = pickle.load(handle)\n",
    "    with open(picklePath + tag + '_initialDict.pickle', 'rb') as handle:\n",
    "        initialDict = pickle.load(handle)\n",
    "    with open(picklePath + tag + '_roundInfos.pickle', 'rb') as handle:\n",
    "        roundInfos = pickle.load(handle)\n",
    "        \n",
    "    initialNameDict = getInitialNameDict(initialDict)\n",
    "    print(\"Original Names : \", initialNameDict)\n",
    "    print(\"round informations\", roundInfos)\n",
    "    \n",
    "    # It have to create the Z structure for drawing purpose.\n",
    "    Z = createStructZ(intermediate, initialNameDict)\n",
    "    \n",
    "    label_list = createLabelList(initialNameDict) # create graph labels by nameDict\n",
    "    (orig_x, orig_y) = plt.rcParams['figure.figsize']\n",
    "    plt.rcParams['figure.figsize'] = (6, 10) #---input\n",
    "\n",
    "    # P = sch.dendrogram(Z, color_threshold = upgma_threshold, orientation = 'right') # no label\n",
    "    P = sch.dendrogram(Z, color_threshold = upgma_threshold, labels = label_list, orientation = 'right')\n",
    "\n",
    "#     plt.axvline(x=upgma_threshold, linewidth=1, color='black', linestyle='--')\n",
    "    locs, labels = plt.yticks()\n",
    "    # plt.xticks(  np.arange(0,1.1,0.1)) #---Align axis-x 900(0, 0.35, 0.05) 909(0,0.6,0.1) 855(0, 0.9, 0.1)\n",
    "    plt.setp(labels, fontsize = 14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = (orig_x, orig_y)\n",
    "    plt.savefig(outputPath+'SBBGCA_'+tag+'.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# usage example of draw hierarchy graph of clustering results\n",
    "familyName = 'eggnog'\n",
    "tag = familyName + \"_0.8\" # used for pickle name\n",
    "# tag = '27fam_cross'\n",
    "outputPath = \"output/RasMMA-test/\"+tag+\"/\"\n",
    "pickleDir = outputPath + \"pickle/\"\n",
    "drawClusteringResults(pickleDir, outputPath, tag, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
