{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 將vtreport副檔名改為txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## add extension .txt\n",
    "# for filename in os.listdir('data/virus_total/'):\n",
    "#     base_file, ext = os.path.splitext(filename)\n",
    "#     if ext != \".txt\":\n",
    "#         os.rename('data/virus_total/'+filename, 'data/virus_total/'+filename + \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_search(in_directory,in_hooklog_directory,in_first_seen=True):\n",
    "# MIKE: 20170822, hack for TXT (VT report) or hooklog\n",
    "#     run_directory = in_hooklog_directory if in_hooklog_directory != None else in_directory\n",
    "\n",
    "    # iter the directory\n",
    "    file_list = next(os.walk(in_hooklog_directory))[2]\n",
    "#     print(file_list)\n",
    "    hash_set = set(t.split('.')[0].split(\"_\")[0] for t in file_list)\n",
    "    ext = file_list[0].split('.')[-1].lower() \n",
    "\n",
    "    print(\"%d files\" % len(file_list))\n",
    "    print(\"%d hashes\" % len(hash_set))\n",
    "#     print(ext)\n",
    "#     print(\"save to\", out_csvfile)\n",
    "#     print(\"save to\", out_wn_csvfile)\n",
    "\n",
    "    # find all anti-virus engines and corresponding detection strings\n",
    "\n",
    "    av_set = set() # set of all anti-virus engines\n",
    "    csv_dict = dict()\n",
    "    unknown = []\n",
    "\n",
    "    for h in hash_set:\n",
    "        # open txt file and load it as json\n",
    "        try:\n",
    "            with open(os.path.join(in_directory, h + '.txt')) as txt_file:    \n",
    "                json_report = json.load(txt_file)\n",
    "#                 print(json_report)\n",
    "        except:\n",
    "            unknown.append(os.path.join(in_directory, h ).split('/')[-1])\n",
    "\n",
    "        # create a dictionary _dict = {engine: \"detection_name\"}\n",
    "        try:\n",
    "            _dict = dict()\n",
    "            for engine in json_report['scans'].keys(): \n",
    "                scan_result = json_report['scans'].get(engine)\n",
    "                if scan_result.get(\"detected\") == True:\n",
    "                    result = scan_result.get(\"result\").encode('ascii', 'ignore')\n",
    "                    result = result.decode(\"ascii\").replace(',', '') # special replacement for csv\n",
    "                    av_set.add(engine)\n",
    "\n",
    "                    _dict[engine] = result\n",
    "\n",
    "            # if you don't need first_seen, set in_first_seen as Fasle\n",
    "            if in_first_seen:\n",
    "                _dict[\"first_seen\"] = json_report['first_seen']\n",
    "\n",
    "            # attach this dictioary to csv_dict = {hash: _dict}\n",
    "            csv_dict[h] = _dict\n",
    "        except Exception as e:\n",
    "            print('!!!!!!!!!!!!!!!!!',str(e),'!!!!!!!!!!!!!!!!!')\n",
    "            pass\n",
    "\n",
    "    print(\"沒有vtreport的數量 / main全部的hash數目 :\",len(unknown), \"/\", len(hash_set))\n",
    "    # unknown\n",
    "\n",
    "    df = pd.DataFrame(csv_dict).T\n",
    "    return df\n",
    "# You can print the df here\n",
    "# df.head()\n",
    "#df['AVG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_T_V(df,in_hooklog_directory,out_train,out_valid,split_rate=0.9):    \n",
    "    sorts = df.filter(['first_seen'])\n",
    "    sorts = sorts.sort_values(['first_seen'],ascending=[1])\n",
    "    sorts = sorts.reset_index()\n",
    "    sorts.columns=['hls','time']\n",
    "    sort = sorts.drop(columns='time')\n",
    "#     sort\n",
    "\n",
    "    split_T = int(len(sorts)*split_rate)\n",
    "    sort_T , sort_V = sort[:split_T], sort[split_T:] \n",
    "    sort_V.reset_index(inplace=True)\n",
    "\n",
    "    if not os.path.isdir(out_train):\n",
    "        os.makedirs(out_train)\n",
    "    for hls in sort_T['hls']:\n",
    "        pattern_ = in_hooklog_directory + str(hls) + \"*\"\n",
    "#         print(pattern_)\n",
    "        whole_name = glob.glob(pattern_)[0]\n",
    "        shutil.copy(whole_name, os.path.join(out_train, whole_name.split('/')[-1]))\n",
    "    print(os.path.join(out_train))\n",
    "    if not os.path.isdir(out_valid):\n",
    "        os.makedirs(out_valid)\n",
    "    for hls in sort_V['hls']:\n",
    "        pattern_ = in_hooklog_directory + str(hls) + \"*\"\n",
    "        whole_name = glob.glob(pattern_)[0]\n",
    "        shutil.copy(whole_name, os.path.join(out_valid,whole_name.split('/')[-1]))\n",
    "    print(os.path.join(out_valid))\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for android\n",
    "\n",
    "def main(in_directory,in_hooklog_directory,out_train,out_valid,split_rate):\n",
    "    \n",
    "    df = pre_search(in_directory,in_hooklog_directory)\n",
    "    try:\n",
    "        split_T_V(df,in_hooklog_directory,out_train,out_valid,split_rate)\n",
    "    except KeyError as e:\n",
    "        print(\"!!!!!!!!\",\"KeyError: \",str(e),'!!!!!!!!!!!')\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from numpy import nan as NaN\n",
    "    import shutil\n",
    "    import glob\n",
    "#     in_tag = \"autoit/main/\"\n",
    "\n",
    "    #PARAMETERS\n",
    "    in_directory = \"./data/VTReport/\" # virus total private key report(包含firstseen)，底下是全部的 .txt\n",
    "    in_hooklog_directorys = \"./data/tracelogs_analysis_temu20/\" # hooklog的根目錄，下面有\"家族family name\"名稱，在下面有\"代別generation\"名稱\n",
    "    split_rate = 0.9 #多少%要當訓練資料\n",
    "    out_trains = 'data/train/' #輸出訓練hooklogs\n",
    "    out_valids = 'data/test/'  #輸出測試hooklogs\n",
    "\n",
    "    \n",
    "    for family in next(os.walk(in_hooklog_directorys))[1]:\n",
    "        print(\"==========\",str(family)+\"/\",\"==========\")\n",
    "        in_hooklog_directory = in_hooklog_directorys+family+\"/\"\n",
    "        out_train = out_trains+family+\"/\"\n",
    "        out_valid = out_valids + family+\"/\"\n",
    "        main(in_directory,in_hooklog_directory,out_train,out_valid,split_rate=0.9)\n",
    "\n",
    "#     in_first_seen = True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
