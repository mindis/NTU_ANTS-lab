# Profile Seq2Seq Model

#### Location: 140.112.107.43/Chih-Chun/Seq2Seq_ApiParam/
#### Environment:
* python 3.6
* Pytorch 0.4.1

## `main.py`
* `python3 main.py {max_trace_length} {batch_size} {dropout} {api_emb_size} {tag_emb_size} {api_call.json path} {dataset_dir} {traindata_dir} {valid_data_dir} {config_dir} {output_dir}`
* `dataset_dir/data/` should contain:
    * ![](https://i.imgur.com/453pzIS.png)
    * `dataset_dir/FeatureVec_clean.csv` should contain the tag mapping from **sha256 to tags**
    * `*Emb.txt` should define the embedding size of each parameter
    * The format should be: **parameter,embedding** size
    * e.g. nominalEmb.txt
    ![](https://i.imgur.com/yFseIcZ.png)
* model configuration can be set in `config/model_config.txt`
* model training configuration can be set in `config/train_config.txt`


## `config/`
![](https://i.imgur.com/qYCg3VM.png)
### `train_config.txt`
* Set training configuration
* ![](https://i.imgur.com/VUhDh37.png)

### `model_config.txt`
* Set LSTM model configuration
   * ![](https://i.imgur.com/y2rraF1.png)

### `wordEnc_config.txt`
* ![](https://i.imgur.com/xkeiaej.png)

### `charEnc_config.txt`
* ![](https://i.imgur.com/dUzmKKL.png)


## `train.py`
* Module for training
* `train(), valid(), maskNLLLoss()`

## `load.py`
* `ApiParamData()`: Module to load Profile data

## `model.py`
* `WordEncoder()`: Module to encode word(or character) into embedding
* `InpEmbedding()`: Module to get the input embedding vector
* `ApiParamEncoder()`:Encoder to encode the input vector
* `Attn()`: Module to get Luong Attention
* `LuongDecoder`: Decoder with Luong Attention

## `predict.py`
* `python3 predict.py {dataset_dir} {config_dir} {encoder_path} {decoder_path} {max_trace_len} {api_emb_size} {tag_emb_size} {api_call_path} {output_dir}`
* The script will output:
    1. `test_predict_all.txt` (prediction per profile)
    2. `test_predict_sha.txt` (prediction per sha256)
    3. `sha256.txt` (all sha256 in testing data, ordered as `test_predict_sha.txt`)
    4. `attn_ws.pickle` ( list contains attention weight for all profile, each weight.shape is **(output_tag_len, input_seq_len)** )

## `plot_attn.ipynb`
* Plot attention Matrix


## `plot_loss.ipynb`
* Plot Training & validation loss


## `evaluation.py`
* `python3 evaluation.py {pred_file_path} {target_file_path} {test_profile_index_path (Profiles.txt or sha256.txt)} {Feature Vector path} {output dir}`

* The script will give following evaluation results:
    1. **`_metrics.csv`: TP, |prediction|, Precision, |ground truth|, Recall, F1**
    2. **`_confusion_mat.csv`: confusion matrix**
    3. **`_rep_tag_num.csv`: Number of repeated tags in prediction**
    4. **`_len_comp.csv`: |ground truth| - |prediction|**
    5. **`_fm_ac_and_mae.txt`: full match accuracy & Length MAE(Mean Absolute Error)**
    6. **`_fullmatch_idx.txt`: full match index**
    7. **`_ave_metrics.txt`: Average TP, Precision, Recall, F1, |prediction|, |ground truth|**


## `getEmb.py`
* `python3 getEmb.py {dataset_dir} {test_dir} {config_dir} {encoder_path} {max_trace_len} {Feature Vector path} {api_call_path} {output dir}`
* The script will output:
    1. **`wordParam.pkl`: word level embedding**
    2. **`charParam.pkl`: char level embedding**

## `plot_embedding.ipynb`
* Plot the word & character level embedding

## `sha2Profile.py`
* `python3 sha2Profile.py {profile_path} {sha256_path} {full match sha256 idx file} {output dir}`
* The script will output **`fm_prf_idx.txt`** which contain the **full match profile index**

## `profile2Sha2Tag.py`
* `python3 profile2Sha2Tag.py {test_dir} {Feature Vector path} {output dir}`
* The script will output:
1. **`target.txt`: target tags per profile**
2. **`sha_target.txt`: target tags per sha256**
3. **`sha256.txt`: all sha256**
